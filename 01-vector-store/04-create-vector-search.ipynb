{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create Vector Search Index\n",
        "\n",
        "This parameterized notebook creates and manages a Databricks Vector Search index.\n",
        "\n",
        "## Workflow\n",
        "\n",
        "1. **Configure** - Set parameters for your table and index\n",
        "2. **Install** - Install databricks-vectorsearch package\n",
        "3. **Verify** - Check endpoint and source table\n",
        "4. **Create** - Create Delta Sync index with managed embeddings\n",
        "5. **Monitor** - Wait for index to be ready\n",
        "6. **Test** - Run sample queries\n",
        "7. **Maintain** - Sync and status functions\n",
        "\n",
        "## Parameters\n",
        "\n",
        "This notebook uses widget parameters for easy customization. Run the Configuration cell to set up widgets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Configuration (Parameterized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PARAMETERIZED CONFIGURATION\n",
        "# =============================================================================\n",
        "# Create widgets for notebook parameters (can be overridden when running as a job)\n",
        "\n",
        "# Remove existing widgets if re-running\n",
        "try:\n",
        "    dbutils.widgets.removeAll()\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Define parameters with defaults for customer reviews use case\n",
        "dbutils.widgets.text(\"catalog\", \"juan_use1_catalog\", \"1. Catalog\")\n",
        "dbutils.widgets.text(\"schema\", \"retail\", \"2. Schema\")\n",
        "dbutils.widgets.text(\"source_table\", \"gold_customer_reviews\", \"3. Source Table\")\n",
        "dbutils.widgets.text(\"index_name\", \"gold_customer_reviews_idx\", \"4. Index Name\")\n",
        "dbutils.widgets.text(\"endpoint_name\", \"one-env-shared-endpoint-11\", \"5. VS Endpoint\")\n",
        "dbutils.widgets.text(\"primary_key\", \"review_id\", \"6. Primary Key Column\")\n",
        "dbutils.widgets.text(\"embedding_column\", \"review_text\", \"7. Embedding Column\")\n",
        "dbutils.widgets.dropdown(\"embedding_model\", \"databricks-gte-large-en\", \n",
        "                         [\"databricks-bge-large-en\", \"databricks-gte-large-en\"], \n",
        "                         \"8. Embedding Model\")\n",
        "dbutils.widgets.dropdown(\"sync_mode\", \"TRIGGERED\", \n",
        "                         [\"TRIGGERED\", \"CONTINUOUS\"], \n",
        "                         \"9. Sync Mode\")\n",
        "dbutils.widgets.text(\"filter_columns\", \"product_category,product_brand,customer_segment,rating\", \n",
        "                     \"10. Filter Columns (comma-separated)\")\n",
        "\n",
        "print(\"‚úì Widgets created - configure values above or use defaults\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load parameters from widgets\n",
        "CATALOG = dbutils.widgets.get(\"catalog\")\n",
        "SCHEMA = dbutils.widgets.get(\"schema\")\n",
        "SOURCE_TABLE = dbutils.widgets.get(\"source_table\")\n",
        "INDEX_NAME = dbutils.widgets.get(\"index_name\")\n",
        "ENDPOINT_NAME = dbutils.widgets.get(\"endpoint_name\")\n",
        "PRIMARY_KEY = dbutils.widgets.get(\"primary_key\")\n",
        "EMBEDDING_COLUMN = dbutils.widgets.get(\"embedding_column\")\n",
        "EMBEDDING_MODEL = dbutils.widgets.get(\"embedding_model\")\n",
        "SYNC_MODE = dbutils.widgets.get(\"sync_mode\")\n",
        "FILTER_COLUMNS = [c.strip() for c in dbutils.widgets.get(\"filter_columns\").split(\",\") if c.strip()]\n",
        "\n",
        "# Construct full names\n",
        "FULL_SOURCE_TABLE = f\"{CATALOG}.{SCHEMA}.{SOURCE_TABLE}\"\n",
        "FULL_INDEX_NAME = f\"{CATALOG}.{SCHEMA}.{INDEX_NAME}\"\n",
        "\n",
        "# Display configuration\n",
        "print(\"=\" * 70)\n",
        "print(\"VECTOR SEARCH INDEX CONFIGURATION\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\"\"\n",
        "  Source Table:     {FULL_SOURCE_TABLE}\n",
        "  Index Name:       {FULL_INDEX_NAME}\n",
        "  Endpoint:         {ENDPOINT_NAME}\n",
        "  \n",
        "  Primary Key:      {PRIMARY_KEY}\n",
        "  Embedding Column: {EMBEDDING_COLUMN}\n",
        "  Embedding Model:  {EMBEDDING_MODEL}\n",
        "  Sync Mode:        {SYNC_MODE}\n",
        "  \n",
        "  Filter Columns:   {FILTER_COLUMNS}\n",
        "\"\"\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Install Vector Search Package\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install databricks-vectorsearch --quiet\n",
        "dbutils.library.restartPython()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# RE-INITIALIZE AFTER PYTHON RESTART\n",
        "# =============================================================================\n",
        "from databricks.vector_search.client import VectorSearchClient\n",
        "import time\n",
        "\n",
        "# Reload parameters after restart\n",
        "CATALOG = dbutils.widgets.get(\"catalog\")\n",
        "SCHEMA = dbutils.widgets.get(\"schema\")\n",
        "SOURCE_TABLE = dbutils.widgets.get(\"source_table\")\n",
        "INDEX_NAME = dbutils.widgets.get(\"index_name\")\n",
        "ENDPOINT_NAME = dbutils.widgets.get(\"endpoint_name\")\n",
        "PRIMARY_KEY = dbutils.widgets.get(\"primary_key\")\n",
        "EMBEDDING_COLUMN = dbutils.widgets.get(\"embedding_column\")\n",
        "EMBEDDING_MODEL = dbutils.widgets.get(\"embedding_model\")\n",
        "SYNC_MODE = dbutils.widgets.get(\"sync_mode\")\n",
        "FILTER_COLUMNS = [c.strip() for c in dbutils.widgets.get(\"filter_columns\").split(\",\") if c.strip()]\n",
        "\n",
        "FULL_SOURCE_TABLE = f\"{CATALOG}.{SCHEMA}.{SOURCE_TABLE}\"\n",
        "FULL_INDEX_NAME = f\"{CATALOG}.{SCHEMA}.{INDEX_NAME}\"\n",
        "\n",
        "# Initialize Vector Search client\n",
        "vsc = VectorSearchClient()\n",
        "print(\"‚úì Vector Search Client initialized\")\n",
        "print(f\"  Target Index: {FULL_INDEX_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Verify Prerequisites\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# VERIFY ENDPOINT\n",
        "# =============================================================================\n",
        "print(\"Checking Vector Search endpoint...\")\n",
        "try:\n",
        "    endpoint = vsc.get_endpoint(ENDPOINT_NAME)\n",
        "    state = endpoint.get('endpoint_status', {}).get('state', 'Unknown')\n",
        "    print(f\"‚úì Endpoint '{ENDPOINT_NAME}' exists\")\n",
        "    print(f\"  State: {state}\")\n",
        "    \n",
        "    if state != 'ONLINE':\n",
        "        print(f\"\\n‚ö†Ô∏è  Warning: Endpoint is not ONLINE (current: {state})\")\n",
        "        print(\"   Wait for endpoint to come online before creating index.\")\n",
        "        ENDPOINT_READY = False\n",
        "    else:\n",
        "        ENDPOINT_READY = True\n",
        "except Exception as e:\n",
        "    print(f\"‚úó Endpoint '{ENDPOINT_NAME}' not found\")\n",
        "    print(f\"  Error: {e}\")\n",
        "    print(\"\\nüìã To create endpoint, go to:\")\n",
        "    print(\"   Databricks UI ‚Üí Compute ‚Üí Vector Search ‚Üí Create Endpoint\")\n",
        "    ENDPOINT_READY = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Enable Change Data Feed\n",
        "Delta Sync Vector Search indexes require Change Data Feed (CDF) to be enabled on the source table. This allows the index to automatically track and sync changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENABLE CHANGE DATA FEED (Required for Delta Sync)\n",
        "# =============================================================================\n",
        "# Vector Search Delta Sync indexes require Change Data Feed (CDF) to be enabled\n",
        "# on the source table. This allows the index to track and sync changes.\n",
        "\n",
        "print(f\"Checking Change Data Feed status for {FULL_SOURCE_TABLE}...\")\n",
        "\n",
        "try:\n",
        "    # Get current table properties\n",
        "    props_df = spark.sql(f\"SHOW TBLPROPERTIES {FULL_SOURCE_TABLE}\")\n",
        "    props = {row['key']: row['value'] for row in props_df.collect()}\n",
        "    \n",
        "    cdf_enabled = props.get('delta.enableChangeDataFeed', 'false').lower() == 'true'\n",
        "    \n",
        "    if cdf_enabled:\n",
        "        print(f\"‚úì Change Data Feed is already enabled\")\n",
        "    else:\n",
        "        print(f\"  Change Data Feed is not enabled. Enabling now...\")\n",
        "        spark.sql(f\"\"\"\n",
        "            ALTER TABLE {FULL_SOURCE_TABLE} \n",
        "            SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\n",
        "        \"\"\")\n",
        "        print(f\"‚úì Change Data Feed enabled successfully\")\n",
        "    \n",
        "    CDF_READY = True\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚úó Error checking/enabling Change Data Feed: {e}\")\n",
        "    print(f\"\\n  Manual fix:\")\n",
        "    print(f\"  ALTER TABLE {FULL_SOURCE_TABLE} SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\")\n",
        "    CDF_READY = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# VERIFY SOURCE TABLE\n",
        "# =============================================================================\n",
        "print(f\"Checking source table: {FULL_SOURCE_TABLE}...\")\n",
        "\n",
        "try:\n",
        "    # Check table exists and get row count\n",
        "    count_df = spark.sql(f\"SELECT COUNT(*) as count FROM {FULL_SOURCE_TABLE}\")\n",
        "    row_count = count_df.collect()[0]['count']\n",
        "    print(f\"‚úì Table exists with {row_count:,} rows\")\n",
        "    \n",
        "    if row_count == 0:\n",
        "        print(\"‚ö†Ô∏è  Warning: Table is empty. Populate data before creating index.\")\n",
        "        TABLE_READY = False\n",
        "    else:\n",
        "        TABLE_READY = True\n",
        "    \n",
        "    # Verify required columns exist\n",
        "    columns = [c.name for c in spark.table(FULL_SOURCE_TABLE).schema]\n",
        "    \n",
        "    missing_cols = []\n",
        "    if PRIMARY_KEY not in columns:\n",
        "        missing_cols.append(f\"Primary key: {PRIMARY_KEY}\")\n",
        "    if EMBEDDING_COLUMN not in columns:\n",
        "        missing_cols.append(f\"Embedding column: {EMBEDDING_COLUMN}\")\n",
        "    for fc in FILTER_COLUMNS:\n",
        "        if fc not in columns:\n",
        "            missing_cols.append(f\"Filter column: {fc}\")\n",
        "    \n",
        "    if missing_cols:\n",
        "        print(f\"\\n‚úó Missing columns:\")\n",
        "        for mc in missing_cols:\n",
        "            print(f\"    - {mc}\")\n",
        "        TABLE_READY = False\n",
        "    else:\n",
        "        print(f\"‚úì All required columns present\")\n",
        "        print(f\"  Primary key: {PRIMARY_KEY}\")\n",
        "        print(f\"  Embedding column: {EMBEDDING_COLUMN}\")\n",
        "        print(f\"  Filter columns: {FILTER_COLUMNS}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚úó Table not found or error: {e}\")\n",
        "    TABLE_READY = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Check for Existing Index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CHECK IF INDEX ALREADY EXISTS\n",
        "# =============================================================================\n",
        "print(f\"Checking for existing index: {FULL_INDEX_NAME}...\")\n",
        "print(f\"  Endpoint: {ENDPOINT_NAME}\")\n",
        "\n",
        "INDEX_EXISTS = False\n",
        "\n",
        "try:\n",
        "    existing_index = vsc.get_index(\n",
        "        endpoint_name=ENDPOINT_NAME,\n",
        "        index_name=FULL_INDEX_NAME\n",
        "    )\n",
        "    status = existing_index.describe()\n",
        "    state = status.get('status', {}).get('state', 'Unknown')\n",
        "    \n",
        "    print(f\"\\n‚ö†Ô∏è  Index '{FULL_INDEX_NAME}' already exists\")\n",
        "    print(f\"   State: {state}\")\n",
        "    \n",
        "    # Show index details\n",
        "    if 'status' in status:\n",
        "        status_info = status['status']\n",
        "        if 'indexed_row_count' in status_info.get('index_details', {}):\n",
        "            print(f\"   Indexed Rows: {status_info['index_details']['indexed_row_count']:,}\")\n",
        "    \n",
        "    INDEX_EXISTS = True\n",
        "    print(\"\\n   To recreate, uncomment and run the deletion cell below.\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚úì Index '{FULL_INDEX_NAME}' does not exist\")\n",
        "    print(\"   Ready to create new index.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# (OPTIONAL) DELETE EXISTING INDEX\n",
        "# =============================================================================\n",
        "# Uncomment the code below to delete an existing index before recreating\n",
        "\n",
        "# if INDEX_EXISTS:\n",
        "#     print(f\"Deleting existing index '{FULL_INDEX_NAME}'...\")\n",
        "#     try:\n",
        "#         vsc.delete_index(FULL_INDEX_NAME)\n",
        "#         print(\"‚úì Index deleted successfully\")\n",
        "#         INDEX_EXISTS = False\n",
        "#         print(\"  You can now proceed to create a new index.\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"‚úó Failed to delete index: {e}\")\n",
        "# else:\n",
        "#     print(\"No existing index to delete.\")\n",
        "\n",
        "print(\"‚¨ÜÔ∏è Uncomment the code above to delete an existing index\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Create Delta Sync Index\n",
        "\n",
        "This creates a vector search index with:\n",
        "- **Delta Sync**: Automatically syncs when source table changes\n",
        "- **Managed Embeddings**: Databricks computes embeddings using the specified model\n",
        "- **Filter Columns**: Pre-filtering for efficient queries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CREATE DELTA SYNC VECTOR SEARCH INDEX\n",
        "# =============================================================================\n",
        "if not INDEX_EXISTS:\n",
        "    print(\"=\" * 70)\n",
        "    print(\"CREATING VECTOR SEARCH INDEX\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\"\"\n",
        "  Endpoint:         {ENDPOINT_NAME}\n",
        "  Source Table:     {FULL_SOURCE_TABLE}\n",
        "  Index Name:       {FULL_INDEX_NAME}\n",
        "  \n",
        "  Primary Key:      {PRIMARY_KEY}\n",
        "  Embedding Column: {EMBEDDING_COLUMN}\n",
        "  Embedding Model:  {EMBEDDING_MODEL}\n",
        "  Sync Mode:        {SYNC_MODE}\n",
        "  Filter Columns:   {FILTER_COLUMNS}\n",
        "\"\"\")\n",
        "    \n",
        "    try:\n",
        "        # Build columns to sync (primary key + embedding + filters)\n",
        "        columns_to_sync = [PRIMARY_KEY, EMBEDDING_COLUMN] + FILTER_COLUMNS\n",
        "        # Remove duplicates while preserving order\n",
        "        columns_to_sync = list(dict.fromkeys(columns_to_sync))\n",
        "        \n",
        "        print(f\"Columns to sync: {columns_to_sync}\")\n",
        "        print(\"\\nCreating index...\")\n",
        "        \n",
        "        index = vsc.create_delta_sync_index(\n",
        "            endpoint_name=ENDPOINT_NAME,\n",
        "            source_table_name=FULL_SOURCE_TABLE,\n",
        "            index_name=FULL_INDEX_NAME,\n",
        "            pipeline_type=SYNC_MODE,\n",
        "            primary_key=PRIMARY_KEY,\n",
        "            embedding_source_column=EMBEDDING_COLUMN,\n",
        "            embedding_model_endpoint_name=EMBEDDING_MODEL,\n",
        "            columns_to_sync=columns_to_sync\n",
        "        )\n",
        "        \n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"‚úì VECTOR SEARCH INDEX CREATION INITIATED\")\n",
        "        print(\"=\" * 70)\n",
        "        print(\"\"\"\n",
        "  Index creation and initial sync may take several minutes.\n",
        "  \n",
        "  Next steps:\n",
        "  1. Run the monitoring cells below to check status\n",
        "  2. Wait for state to become ONLINE\n",
        "  3. For TRIGGERED mode, manually sync after data updates\n",
        "\"\"\")\n",
        "        INDEX_EXISTS = True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚úó Failed to create index: {e}\")\n",
        "        print(\"\\nTroubleshooting:\")\n",
        "        print(\"  - Ensure endpoint is ONLINE\")\n",
        "        print(\"  - Verify source table has data\")\n",
        "        print(\"  - Check Change Data Feed is enabled on source table:\")\n",
        "        print(f\"    ALTER TABLE {FULL_SOURCE_TABLE} SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\")\n",
        "        print(\"  - Verify you have permissions to create indexes\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Index already exists. Skipping creation.\")\n",
        "    print(\"   To recreate, delete the existing index first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Monitor Index Status\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# INDEX STATUS FUNCTIONS\n",
        "# =============================================================================\n",
        "def check_index_status(index_name=None, endpoint_name=None):\n",
        "    \"\"\"Check and display current index status.\"\"\"\n",
        "    # Resolve names from parameters or globals/widgets\n",
        "    if index_name is None:\n",
        "        try:\n",
        "            index_name = FULL_INDEX_NAME\n",
        "        except NameError:\n",
        "            cat = dbutils.widgets.get(\"catalog\")\n",
        "            sch = dbutils.widgets.get(\"schema\")\n",
        "            idx = dbutils.widgets.get(\"index_name\")\n",
        "            index_name = f\"{cat}.{sch}.{idx}\"\n",
        "    \n",
        "    if endpoint_name is None:\n",
        "        try:\n",
        "            endpoint_name = ENDPOINT_NAME\n",
        "        except NameError:\n",
        "            endpoint_name = dbutils.widgets.get(\"endpoint_name\")\n",
        "    \n",
        "    try:\n",
        "        index = vsc.get_index(endpoint_name=endpoint_name, index_name=index_name)\n",
        "        status = index.describe()\n",
        "        \n",
        "        print(\"=\" * 60)\n",
        "        print(f\"INDEX STATUS: {index_name}\")\n",
        "        print(f\"ENDPOINT: {endpoint_name}\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        state = status.get('status', {}).get('state', 'Unknown')\n",
        "        print(f\"  State: {state}\")\n",
        "        \n",
        "        status_info = status.get('status', {})\n",
        "        if 'detailed_state' in status_info:\n",
        "            print(f\"  Detailed State: {status_info['detailed_state']}\")\n",
        "        if 'message' in status_info:\n",
        "            print(f\"  Message: {status_info['message']}\")\n",
        "        if 'index_details' in status_info:\n",
        "            details = status_info['index_details']\n",
        "            if 'indexed_row_count' in details:\n",
        "                print(f\"  Indexed Rows: {details['indexed_row_count']:,}\")\n",
        "            if 'pending_row_count' in details:\n",
        "                print(f\"  Pending Rows: {details['pending_row_count']:,}\")\n",
        "        \n",
        "        print(\"=\" * 60)\n",
        "        return status\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚úó Error checking index status: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def wait_for_index_online(index_name=None, endpoint_name=None, max_wait_minutes=30, check_interval_seconds=30):\n",
        "    \"\"\"Wait for index to reach ONLINE state.\"\"\"\n",
        "    # Resolve names\n",
        "    if index_name is None:\n",
        "        try:\n",
        "            index_name = FULL_INDEX_NAME\n",
        "        except NameError:\n",
        "            cat = dbutils.widgets.get(\"catalog\")\n",
        "            sch = dbutils.widgets.get(\"schema\")\n",
        "            idx = dbutils.widgets.get(\"index_name\")\n",
        "            index_name = f\"{cat}.{sch}.{idx}\"\n",
        "    \n",
        "    if endpoint_name is None:\n",
        "        try:\n",
        "            endpoint_name = ENDPOINT_NAME\n",
        "        except NameError:\n",
        "            endpoint_name = dbutils.widgets.get(\"endpoint_name\")\n",
        "    \n",
        "    print(f\"Waiting for index to be ONLINE (max {max_wait_minutes} minutes)...\")\n",
        "    print(f\"  Index: {index_name}\")\n",
        "    print(f\"  Endpoint: {endpoint_name}\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    max_wait_seconds = max_wait_minutes * 60\n",
        "    \n",
        "    while time.time() - start_time < max_wait_seconds:\n",
        "        elapsed_min = int((time.time() - start_time) / 60)\n",
        "        \n",
        "        try:\n",
        "            index = vsc.get_index(endpoint_name=endpoint_name, index_name=index_name)\n",
        "            status = index.describe()\n",
        "            state = status.get('status', {}).get('state', 'Unknown')\n",
        "            \n",
        "            if state == 'ONLINE':\n",
        "                print(f\"\\n‚úì Index is ONLINE after {elapsed_min} minutes!\")\n",
        "                return True\n",
        "            else:\n",
        "                indexed = status.get('status', {}).get('index_details', {}).get('indexed_row_count', '?')\n",
        "                print(f\"  [{elapsed_min}m] State: {state} | Indexed: {indexed}\")\n",
        "                time.sleep(check_interval_seconds)\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"  [{elapsed_min}m] Error: {e}\")\n",
        "            time.sleep(check_interval_seconds)\n",
        "    \n",
        "    print(f\"\\n‚ö†Ô∏è  Timeout after {max_wait_minutes} minutes. Index may still be provisioning.\")\n",
        "    return False\n",
        "\n",
        "\n",
        "print(\"‚úì Status functions defined:\")\n",
        "print(\"  - check_index_status(): Show current index state\")\n",
        "print(\"  - wait_for_index_online(): Wait for ONLINE state\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check current index status\n",
        "check_index_status()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wait for index to be online (uncomment to use)\n",
        "# wait_for_index_online(max_wait_minutes=15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Trigger Sync (for TRIGGERED mode)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SYNC FUNCTION\n",
        "# =============================================================================\n",
        "def sync_index(index_name=None, endpoint_name=None):\n",
        "    \"\"\"Trigger a manual sync for the index (TRIGGERED mode only).\"\"\"\n",
        "    # Resolve names\n",
        "    if index_name is None:\n",
        "        try:\n",
        "            index_name = FULL_INDEX_NAME\n",
        "        except NameError:\n",
        "            cat = dbutils.widgets.get(\"catalog\")\n",
        "            sch = dbutils.widgets.get(\"schema\")\n",
        "            idx = dbutils.widgets.get(\"index_name\")\n",
        "            index_name = f\"{cat}.{sch}.{idx}\"\n",
        "    \n",
        "    if endpoint_name is None:\n",
        "        try:\n",
        "            endpoint_name = ENDPOINT_NAME\n",
        "        except NameError:\n",
        "            endpoint_name = dbutils.widgets.get(\"endpoint_name\")\n",
        "    \n",
        "    try:\n",
        "        index = vsc.get_index(endpoint_name=endpoint_name, index_name=index_name)\n",
        "        index.sync()\n",
        "        print(f\"‚úì Sync triggered for '{index_name}'\")\n",
        "        print(f\"  Endpoint: {endpoint_name}\")\n",
        "        print(\"  Check status in a few moments to monitor progress.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚úó Failed to trigger sync: {e}\")\n",
        "        return False\n",
        "\n",
        "print(\"‚úì Sync function defined:\")\n",
        "print(\"  - sync_index(): Trigger manual sync for TRIGGERED mode\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trigger sync (uncomment to use after data updates)\n",
        "# sync_index()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Test Queries\n",
        "\n",
        "Once the index is ONLINE, test with sample queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# TEST QUERY FUNCTION\n",
        "# =============================================================================\n",
        "def test_query(query_text, num_results=5, filters=None, index_name=None, endpoint_name=None):\n",
        "    \"\"\"\n",
        "    Test the vector search index with a similarity query.\n",
        "    \n",
        "    Args:\n",
        "        query_text: Natural language query\n",
        "        num_results: Number of results to return\n",
        "        filters: Filter dict for standard endpoints (e.g., {\"product_category\": \"footwear\"})\n",
        "                 or filter string for storage-optimized endpoints\n",
        "        index_name: Index to query (defaults to configured index)\n",
        "        endpoint_name: Vector Search endpoint name\n",
        "    \n",
        "    Returns:\n",
        "        Query results\n",
        "    \"\"\"\n",
        "    # Resolve index name from parameter, global, or widget\n",
        "    if index_name is None:\n",
        "        try:\n",
        "            index_name = FULL_INDEX_NAME\n",
        "        except NameError:\n",
        "            try:\n",
        "                cat = dbutils.widgets.get(\"catalog\")\n",
        "                sch = dbutils.widgets.get(\"schema\")\n",
        "                idx = dbutils.widgets.get(\"index_name\")\n",
        "                index_name = f\"{cat}.{sch}.{idx}\"\n",
        "            except:\n",
        "                print(\"‚úó Index name not specified.\")\n",
        "                print(\"  Run configuration cells first or pass index_name parameter.\")\n",
        "                return None\n",
        "    \n",
        "    # Resolve endpoint name\n",
        "    if endpoint_name is None:\n",
        "        try:\n",
        "            endpoint_name = ENDPOINT_NAME\n",
        "        except NameError:\n",
        "            try:\n",
        "                endpoint_name = dbutils.widgets.get(\"endpoint_name\")\n",
        "            except:\n",
        "                print(\"‚úó Endpoint name not specified.\")\n",
        "                print(\"  Run configuration cells first or pass endpoint_name parameter.\")\n",
        "                return None\n",
        "    \n",
        "    # Resolve column names\n",
        "    try:\n",
        "        pk, emb_col = PRIMARY_KEY, EMBEDDING_COLUMN\n",
        "        filter_cols = FILTER_COLUMNS[:3]\n",
        "    except NameError:\n",
        "        try:\n",
        "            pk = dbutils.widgets.get(\"primary_key\")\n",
        "            emb_col = dbutils.widgets.get(\"embedding_column\")\n",
        "            filter_cols = [c.strip() for c in dbutils.widgets.get(\"filter_columns\").split(\",\")[:3]]\n",
        "        except:\n",
        "            pk, emb_col = \"review_id\", \"review_text\"\n",
        "            filter_cols = [\"product_category\", \"customer_segment\", \"rating\"]\n",
        "    \n",
        "    display_cols = [pk, emb_col] + filter_cols\n",
        "    \n",
        "    try:\n",
        "        index = vsc.get_index(endpoint_name=endpoint_name, index_name=index_name)\n",
        "        \n",
        "        query_params = {\n",
        "            \"query_text\": query_text,\n",
        "            \"columns\": display_cols,\n",
        "            \"num_results\": num_results\n",
        "        }\n",
        "        if filters:\n",
        "            query_params[\"filters\"] = filters\n",
        "        \n",
        "        results = index.similarity_search(**query_params)\n",
        "        \n",
        "        print(\"=\" * 70)\n",
        "        print(f\"QUERY: \\\"{query_text}\\\"\")\n",
        "        print(f\"INDEX: {index_name}\")\n",
        "        if filters:\n",
        "            print(f\"FILTER: {filters}\")\n",
        "        print(\"=\" * 70)\n",
        "        \n",
        "        data = results.get('result', {}).get('data_array', [])\n",
        "        print(f\"Found {len(data)} results\\n\")\n",
        "        \n",
        "        for i, row in enumerate(data, 1):\n",
        "            print(f\"Result {i}:\")\n",
        "            for j, col_name in enumerate(display_cols):\n",
        "                if j < len(row):\n",
        "                    value = row[j]\n",
        "                    if col_name == emb_col and len(str(value)) > 100:\n",
        "                        value = str(value)[:100] + \"...\"\n",
        "                    print(f\"  {col_name}: {value}\")\n",
        "            print()\n",
        "        \n",
        "        return results\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚úó Query failed: {e}\")\n",
        "        print(f\"  Index: {index_name}\")\n",
        "        print(f\"  Endpoint: {endpoint_name}\")\n",
        "        print(\"  Troubleshooting:\")\n",
        "        print(\"    1. Run check_index_status() to verify index is ONLINE\")\n",
        "        print(\"    2. Ensure VectorSearchClient is initialized (Step 2)\")\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"‚úì Query function defined:\")\n",
        "print(\"  - test_query(query_text, num_results=5, filters=None)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SAMPLE TEST QUERIES (for customer reviews)\n",
        "# =============================================================================\n",
        "# Uncomment and run when index is ONLINE\n",
        "# (test_query auto-loads config from widgets if needed)\n",
        "#\n",
        "# NOTE: Standard endpoints use DICT filters: {\"column\": \"value\"}\n",
        "#       Storage-optimized endpoints use STRING filters: \"column = 'value'\"\n",
        "\n",
        "# Basic similarity search\n",
        "test_query(\"sizing runs small need to order larger size\")\n",
        "\n",
        "# Search with filter (dict format for standard endpoints)\n",
        "# test_query(\"comfortable shoes great for walking\", filters={\"product_category\": \"footwear\"})\n",
        "\n",
        "# Search for quality issues\n",
        "# test_query(\"poor quality fabric feels cheap\", num_results=3)\n",
        "\n",
        "# Search by customer segment\n",
        "# test_query(\"excellent service highly recommend\", filters={\"customer_segment\": \"vip\"})\n",
        "\n",
        "# Search with multiple filter values (matches ANY of the values)\n",
        "# test_query(\"great quality material\", filters={\"product_category\": [\"footwear\", \"outerwear\"]})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: SQL Query Examples\n",
        "\n",
        "You can also query the index using the SQL `VECTOR_SEARCH` function.\n",
        "\n",
        "**Note**: SQL uses string-style filters (different from Python SDK dict filters).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SQL VECTOR SEARCH EXAMPLES\n",
        "# =============================================================================\n",
        "# These queries can be run once the index is ONLINE\n",
        "\n",
        "sql_examples = f\"\"\"\n",
        "-- Basic similarity search\n",
        "SELECT * FROM VECTOR_SEARCH(\n",
        "  index => '{FULL_INDEX_NAME}',\n",
        "  query => 'sizing runs small need to order larger',\n",
        "  num_results => 10\n",
        ")\n",
        "\n",
        "-- Search with filter\n",
        "SELECT * FROM VECTOR_SEARCH(\n",
        "  index => '{FULL_INDEX_NAME}',\n",
        "  query => 'comfortable shoes excellent quality',\n",
        "  num_results => 10,\n",
        "  filters => 'product_category = \"footwear\"'\n",
        ")\n",
        "\n",
        "-- Join with source table for additional columns\n",
        "SELECT vs.*, src.rating, src.review_date\n",
        "FROM VECTOR_SEARCH(\n",
        "  index => '{FULL_INDEX_NAME}',\n",
        "  query => 'shipping was fast arrived early',\n",
        "  num_results => 5\n",
        ") AS vs\n",
        "LEFT JOIN {FULL_SOURCE_TABLE} AS src\n",
        "  ON vs.{PRIMARY_KEY} = src.{PRIMARY_KEY}\n",
        "\"\"\"\n",
        "\n",
        "print(\"SQL VECTOR_SEARCH Examples:\")\n",
        "print(\"=\" * 70)\n",
        "print(sql_examples)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run SQL vector search (uncomment when index is ONLINE)\n",
        "# display(spark.sql(f\"\"\"\n",
        "#     SELECT * FROM VECTOR_SEARCH(\n",
        "#       index => '{FULL_INDEX_NAME}',\n",
        "#       query => 'sizing runs small need to order larger',\n",
        "#       num_results => 5\n",
        "#     )\n",
        "# \"\"\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Summary & Next Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SUMMARY\n",
        "# =============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"VECTOR SEARCH INDEX SETUP SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\"\"\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  INDEX CONFIGURATION                                                ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ  Index Name:      {FULL_INDEX_NAME:<45} ‚îÇ\n",
        "‚îÇ  Endpoint:        {ENDPOINT_NAME:<45} ‚îÇ\n",
        "‚îÇ  Source Table:    {FULL_SOURCE_TABLE:<45} ‚îÇ\n",
        "‚îÇ  Embedding Model: {EMBEDDING_MODEL:<45} ‚îÇ\n",
        "‚îÇ  Sync Mode:       {SYNC_MODE:<45} ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  AVAILABLE FUNCTIONS                                                ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ  check_index_status()     - View current index state                ‚îÇ\n",
        "‚îÇ  wait_for_index_online()  - Wait for ONLINE state                   ‚îÇ\n",
        "‚îÇ  sync_index()             - Trigger manual sync (TRIGGERED mode)    ‚îÇ\n",
        "‚îÇ  test_query(text)         - Run similarity search                   ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  NEXT STEPS                                                         ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ  1. Wait for index to reach ONLINE state                            ‚îÇ\n",
        "‚îÇ  2. For TRIGGERED mode, run sync_index() after data updates         ‚îÇ\n",
        "‚îÇ  3. Test queries using test_query() or SQL VECTOR_SEARCH            ‚îÇ\n",
        "‚îÇ  4. Integrate with Knowledge Assistant Agent or application         ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  MAINTENANCE                                                        ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ  ‚Ä¢ TRIGGERED mode: Call sync_index() after source table updates     ‚îÇ\n",
        "‚îÇ  ‚Ä¢ CONTINUOUS mode: Syncs automatically (uses more resources)       ‚îÇ\n",
        "‚îÇ  ‚Ä¢ Monitor status with check_index_status()                         ‚îÇ\n",
        "‚îÇ  ‚Ä¢ Delete and recreate if schema changes significantly              ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\"\"\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"‚úì Notebook complete!\")\n",
        "print(\"=\" * 70)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
