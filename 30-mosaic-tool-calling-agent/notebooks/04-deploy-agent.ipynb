{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04: Deploy Multi-Agent System to Model Serving\n",
    "\n",
    "Deploy the Unity Catalog registered agent to a Databricks Model Serving endpoint.\n",
    "\n",
    "**What this notebook does**:\n",
    "1. Creates or updates a Model Serving endpoint\n",
    "2. Deploys the UC model with proper configuration\n",
    "3. Validates the deployment with comprehensive tests\n",
    "4. Provides endpoint information for integration\n",
    "\n",
    "**Prerequisites**:\n",
    "- Model registered in Unity Catalog (`juan_dev.genai.retail_multi_genie_agent`)\n",
    "- Model tested successfully (see `03-test-agent.ipynb`)\n",
    "- Proper permissions on Unity Catalog model\n",
    "- Model Serving permissions in Databricks workspace\n",
    "\n",
    "**Endpoint Configuration**:\n",
    "- **Name**: `retail-multi-genie-agent`\n",
    "- **Model**: `juan_dev.genai.retail_multi_genie_agent`\n",
    "- **Workload**: CPU Small (suitable for agent orchestration)\n",
    "- **Scale to Zero**: Enabled (cost optimization)\n",
    "- **Authentication**: Automatic passthrough via Genie Space resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade databricks-sdk mlflow\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Configure the endpoint and model details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import EndpointCoreConfigInput, ServedEntityInput\n",
    "import time\n",
    "\n",
    "# Initialize workspace client\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# Unity Catalog model configuration\n",
    "UC_MODEL_NAME = \"juan_dev.genai.retail_multi_genie_agent\"\n",
    "\n",
    "# Endpoint configuration\n",
    "ENDPOINT_NAME = \"retail-multi-genie-agent\"\n",
    "\n",
    "# Model version selection (choose one):\n",
    "# Option 1: Use alias (recommended for production)\n",
    "MODEL_VERSION = \"challenger\"  # or \"champion\", \"staging\"\n",
    "MODEL_REFERENCE = f\"{UC_MODEL_NAME}@{MODEL_VERSION}\"\n",
    "\n",
    "# Option 2: Use specific version (uncomment to use)\n",
    "# MODEL_VERSION = \"1\"\n",
    "# MODEL_REFERENCE = f\"{UC_MODEL_NAME}/{MODEL_VERSION}\"\n",
    "\n",
    "# Option 3: Use latest version (uncomment to use)\n",
    "# MODEL_REFERENCE = f\"{UC_MODEL_NAME}/latest\"\n",
    "\n",
    "# Workload configuration\n",
    "WORKLOAD_SIZE = \"Small\"  # Small, Medium, Large\n",
    "WORKLOAD_TYPE = \"CPU\"     # CPU workload (not GPU - this is orchestration, not inference)\n",
    "SCALE_TO_ZERO = True      # Enable cost optimization\n",
    "\n",
    "print(f\"Endpoint Name: {ENDPOINT_NAME}\")\n",
    "print(f\"Model Reference: {MODEL_REFERENCE}\")\n",
    "print(f\"Workload: {WORKLOAD_TYPE} {WORKLOAD_SIZE}\")\n",
    "print(f\"Scale to Zero: {SCALE_TO_ZERO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Existing Endpoint\n",
    "\n",
    "Check if the endpoint already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if endpoint exists\n",
    "endpoint_exists = False\n",
    "try:\n",
    "    existing_endpoint = w.serving_endpoints.get(ENDPOINT_NAME)\n",
    "    endpoint_exists = True\n",
    "    print(f\"‚úÖ Endpoint '{ENDPOINT_NAME}' already exists\")\n",
    "    print(f\"   Current state: {existing_endpoint.state.config_update}\")\n",
    "    print(f\"\\nWill UPDATE existing endpoint with new model version\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ÑπÔ∏è  Endpoint '{ENDPOINT_NAME}' does not exist\")\n",
    "    print(f\"\\nWill CREATE new endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Update Serving Endpoint\n",
    "\n",
    "Deploy the model to a Model Serving endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint configuration\n",
    "endpoint_config = EndpointCoreConfigInput(\n",
    "    name=ENDPOINT_NAME,\n",
    "    served_entities=[\n",
    "        ServedEntityInput(\n",
    "            entity_name=UC_MODEL_NAME,\n",
    "            entity_version=MODEL_VERSION,\n",
    "            workload_size=WORKLOAD_SIZE,\n",
    "            scale_to_zero_enabled=SCALE_TO_ZERO\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "if endpoint_exists:\n",
    "    # Update existing endpoint\n",
    "    print(f\"Updating endpoint '{ENDPOINT_NAME}'...\")\n",
    "    w.serving_endpoints.update_config(\n",
    "        name=ENDPOINT_NAME,\n",
    "        served_entities=endpoint_config.served_entities\n",
    "    )\n",
    "    print(f\"‚úÖ Endpoint update initiated\")\n",
    "else:\n",
    "    # Create new endpoint\n",
    "    print(f\"Creating endpoint '{ENDPOINT_NAME}'...\")\n",
    "    w.serving_endpoints.create(\n",
    "        name=ENDPOINT_NAME,\n",
    "        config=endpoint_config\n",
    "    )\n",
    "    print(f\"‚úÖ Endpoint creation initiated\")\n",
    "\n",
    "print(f\"\\nDeployment started. Waiting for endpoint to be ready...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait for Endpoint Ready\n",
    "\n",
    "Poll the endpoint until it reaches READY state.\n",
    "\n",
    "**Note**: This can take 10-15 minutes for initial deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def wait_for_endpoint_ready(endpoint_name, timeout_minutes=20):\n",
    "    \"\"\"Wait for endpoint to reach READY state\"\"\"\n",
    "    start_time = time.time()\n",
    "    timeout_seconds = timeout_minutes * 60\n",
    "    \n",
    "    print(f\"Waiting for endpoint '{endpoint_name}' to be ready...\")\n",
    "    print(f\"Timeout: {timeout_minutes} minutes\\n\")\n",
    "    \n",
    "    last_state = None\n",
    "    while (time.time() - start_time) < timeout_seconds:\n",
    "        try:\n",
    "            endpoint = w.serving_endpoints.get(endpoint_name)\n",
    "            current_state = endpoint.state.ready\n",
    "            \n",
    "            # Print status update if changed\n",
    "            if current_state != last_state:\n",
    "                elapsed = int(time.time() - start_time)\n",
    "                timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "                print(f\"[{timestamp}] ({elapsed}s) State: {current_state}\")\n",
    "                last_state = current_state\n",
    "            \n",
    "            # Check if ready\n",
    "            if current_state == \"READY\":\n",
    "                elapsed = int(time.time() - start_time)\n",
    "                print(f\"\\n‚úÖ Endpoint is READY! (took {elapsed}s)\")\n",
    "                return True\n",
    "            \n",
    "            # Check for failure states\n",
    "            if current_state in [\"FAILED\", \"UNHEALTHY\"]:\n",
    "                print(f\"\\n‚ùå Endpoint deployment failed with state: {current_state}\")\n",
    "                if hasattr(endpoint.state, 'config_update'):\n",
    "                    print(f\"   Config update status: {endpoint.state.config_update}\")\n",
    "                return False\n",
    "            \n",
    "            # Wait before next check\n",
    "            time.sleep(30)  # Check every 30 seconds\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error checking endpoint status: {e}\")\n",
    "            time.sleep(30)\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è  Timeout after {timeout_minutes} minutes\")\n",
    "    return False\n",
    "\n",
    "# Wait for endpoint\n",
    "is_ready = wait_for_endpoint_ready(ENDPOINT_NAME, timeout_minutes=20)\n",
    "\n",
    "if not is_ready:\n",
    "    print(\"\\n‚ö†Ô∏è  Endpoint is not ready. Check the Model Serving UI for details.\")\n",
    "    print(f\"   UI: /ml/endpoints/{ENDPOINT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Endpoint Information\n",
    "\n",
    "Display endpoint details and scoring URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get endpoint details\n",
    "endpoint = w.serving_endpoints.get(ENDPOINT_NAME)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ENDPOINT INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Name: {endpoint.name}\")\n",
    "print(f\"State: {endpoint.state.ready}\")\n",
    "print(f\"\\nModel:\")\n",
    "print(f\"  - {UC_MODEL_NAME}\")\n",
    "print(f\"  - Version/Alias: {MODEL_VERSION}\")\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  - Workload: {WORKLOAD_TYPE} {WORKLOAD_SIZE}\")\n",
    "print(f\"  - Scale to Zero: {SCALE_TO_ZERO}\")\n",
    "\n",
    "# Get serving URI\n",
    "if hasattr(endpoint, 'config') and hasattr(endpoint.config, 'served_entities'):\n",
    "    for entity in endpoint.config.served_entities:\n",
    "        print(f\"\\nServed Entity:\")\n",
    "        print(f\"  - Name: {entity.entity_name}\")\n",
    "        print(f\"  - Version: {entity.entity_version}\")\n",
    "\n",
    "print(f\"\\nEndpoint URL: /ml/endpoints/{ENDPOINT_NAME}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Endpoint - Single Domain Query\n",
    "\n",
    "Test the deployed endpoint with a simple inventory query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Get workspace URL and token\n",
    "workspace_url = w.config.host\n",
    "token = w.config.token\n",
    "\n",
    "# Endpoint URL\n",
    "endpoint_url = f\"{workspace_url}/serving-endpoints/{ENDPOINT_NAME}/invocations\"\n",
    "\n",
    "# Test query\n",
    "test_query = \"What 5 products are at risk for overstock?\"\n",
    "\n",
    "# Request payload\n",
    "payload = {\n",
    "    \"input\": [\n",
    "        {\"role\": \"user\", \"content\": test_query}\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"Testing endpoint with query: {test_query}\\n\")\n",
    "\n",
    "# Make request\n",
    "start_time = time.time()\n",
    "response = requests.post(\n",
    "    endpoint_url,\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    json=payload\n",
    ")\n",
    "elapsed_ms = (time.time() - start_time) * 1000\n",
    "\n",
    "# Check response\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(f\"Response Time: {elapsed_ms:.0f}ms\")\n",
    "    print(f\"\\nResponse:\")\n",
    "    \n",
    "    # Extract and display response text\n",
    "    if 'output' in result and len(result['output']) > 0:\n",
    "        response_text = result['output'][0].get('text', str(result['output'][0]))\n",
    "        print(response_text)\n",
    "    else:\n",
    "        print(json.dumps(result, indent=2))\n",
    "    \n",
    "    # Validation\n",
    "    assert elapsed_ms < 90000, f\"Response time {elapsed_ms}ms exceeds 90s limit\"\n",
    "    print(f\"\\n‚úÖ Single domain query test PASSED\")\n",
    "else:\n",
    "    print(f\"‚ùå Request failed with status {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Endpoint - Multi-Domain Query\n",
    "\n",
    "Test with a query that spans both customer behavior and inventory domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-domain test query\n",
    "test_query = \"What products are frequently abandoned in carts and do we have inventory issues with those items?\"\n",
    "\n",
    "# Request payload\n",
    "payload = {\n",
    "    \"input\": [\n",
    "        {\"role\": \"user\", \"content\": test_query}\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"Testing multi-domain query: {test_query}\\n\")\n",
    "\n",
    "# Make request\n",
    "start_time = time.time()\n",
    "response = requests.post(\n",
    "    endpoint_url,\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    json=payload\n",
    ")\n",
    "elapsed_ms = (time.time() - start_time) * 1000\n",
    "\n",
    "# Check response\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(f\"Response Time: {elapsed_ms:.0f}ms\")\n",
    "    print(f\"\\nResponse:\")\n",
    "    \n",
    "    # Extract and display response text\n",
    "    if 'output' in result and len(result['output']) > 0:\n",
    "        response_text = result['output'][0].get('text', str(result['output'][0]))\n",
    "        print(response_text)\n",
    "        \n",
    "        # Check domain coverage\n",
    "        response_lower = response_text.lower()\n",
    "        has_customer = any(kw in response_lower for kw in [\"abandon\", \"cart\", \"customer\"])\n",
    "        has_inventory = any(kw in response_lower for kw in [\"inventory\", \"stock\", \"overstock\"])\n",
    "        \n",
    "        print(f\"\\nDomain Coverage:\")\n",
    "        print(f\"  Customer Behavior: {'‚úÖ' if has_customer else '‚ùå'}\")\n",
    "        print(f\"  Inventory: {'‚úÖ' if has_inventory else '‚ùå'}\")\n",
    "    else:\n",
    "        print(json.dumps(result, indent=2))\n",
    "    \n",
    "    # Validation\n",
    "    assert elapsed_ms < 90000, f\"Response time {elapsed_ms}ms exceeds 90s limit\"\n",
    "    print(f\"\\n‚úÖ Multi-domain query test PASSED\")\n",
    "else:\n",
    "    print(f\"‚ùå Request failed with status {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Endpoint - Conversation Context\n",
    "\n",
    "Test conversation history with follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First query\n",
    "query1 = \"What are the top 3 customers by purchase amount?\"\n",
    "\n",
    "payload1 = {\n",
    "    \"input\": [\n",
    "        {\"role\": \"user\", \"content\": query1}\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(f\"Query 1: {query1}\\n\")\n",
    "\n",
    "# First request\n",
    "response1 = requests.post(\n",
    "    endpoint_url,\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    json=payload1\n",
    ")\n",
    "\n",
    "if response1.status_code == 200:\n",
    "    result1 = response1.json()\n",
    "    response_text1 = result1['output'][0].get('text', str(result1['output'][0]))\n",
    "    print(f\"Response 1:\\n{response_text1}\\n\")\n",
    "    \n",
    "    # Follow-up query with context\n",
    "    query2 = \"What products do they purchase most frequently?\"\n",
    "    \n",
    "    payload2 = {\n",
    "        \"input\": [\n",
    "            {\"role\": \"user\", \"content\": query1},\n",
    "            {\"role\": \"assistant\", \"content\": response_text1},\n",
    "            {\"role\": \"user\", \"content\": query2}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(f\"Query 2 (follow-up): {query2}\\n\")\n",
    "    \n",
    "    # Second request with context\n",
    "    response2 = requests.post(\n",
    "        endpoint_url,\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {token}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        },\n",
    "        json=payload2\n",
    "    )\n",
    "    \n",
    "    if response2.status_code == 200:\n",
    "        result2 = response2.json()\n",
    "        response_text2 = result2['output'][0].get('text', str(result2['output'][0]))\n",
    "        print(f\"Response 2:\\n{response_text2}\")\n",
    "        print(f\"\\n‚úÖ Conversation context test PASSED\")\n",
    "    else:\n",
    "        print(f\"‚ùå Follow-up request failed: {response2.status_code}\")\n",
    "else:\n",
    "    print(f\"‚ùå Initial request failed: {response1.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Validation\n",
    "\n",
    "Run multiple queries to validate consistent performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance test queries\n",
    "test_queries = [\n",
    "    \"What is the cart abandonment rate?\",\n",
    "    \"Which products are at risk of stockout?\",\n",
    "    \"Show me customer segments with high purchase frequency\",\n",
    "    \"What items have overstock issues?\",\n",
    "    \"Analyze cart abandonment by product category\"\n",
    "]\n",
    "\n",
    "print(\"Running performance tests...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "response_times = []\n",
    "success_count = 0\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    payload = {\n",
    "        \"input\": [{\"role\": \"user\", \"content\": query}]\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    response = requests.post(\n",
    "        endpoint_url,\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {token}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        },\n",
    "        json=payload\n",
    "    )\n",
    "    elapsed_ms = (time.time() - start_time) * 1000\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_times.append(elapsed_ms)\n",
    "        success_count += 1\n",
    "        status = \"‚úÖ\" if elapsed_ms < 90000 else \"‚ö†Ô∏è\"\n",
    "        print(f\"{status} Query {i}: {elapsed_ms:.0f}ms\")\n",
    "        print(f\"   {query[:50]}...\" if len(query) > 50 else f\"   {query}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Query {i}: Failed ({response.status_code})\")\n",
    "        print(f\"   {query[:50]}...\" if len(query) > 50 else f\"   {query}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nPerformance Summary:\")\n",
    "print(f\"  Successful: {success_count}/{len(test_queries)}\")\n",
    "if response_times:\n",
    "    print(f\"  Avg Response Time: {sum(response_times)/len(response_times):.0f}ms\")\n",
    "    print(f\"  Min Response Time: {min(response_times):.0f}ms\")\n",
    "    print(f\"  Max Response Time: {max(response_times):.0f}ms\")\n",
    "    \n",
    "    # Check if all under 90s\n",
    "    all_under_limit = all(t < 90000 for t in response_times)\n",
    "    if all_under_limit:\n",
    "        print(f\"\\n‚úÖ All queries completed under 90s limit\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Some queries exceeded 90s limit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint Usage Example\n",
    "\n",
    "Example code for calling the endpoint from external applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ENDPOINT USAGE EXAMPLE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\\n# Python Example\n",
    "import requests\n",
    "\n",
    "endpoint_url = \"{workspace_url}/serving-endpoints/{ENDPOINT_NAME}/invocations\"\n",
    "token = \"YOUR_DATABRICKS_TOKEN\"\n",
    "\n",
    "payload = {{\n",
    "    \"input\": [\n",
    "        {{\"role\": \"user\", \"content\": \"What products are at risk for overstock?\"}}\n",
    "    ]\n",
    "}}\n",
    "\n",
    "response = requests.post(\n",
    "    endpoint_url,\n",
    "    headers={{\n",
    "        \"Authorization\": f\"Bearer {{token}}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }},\n",
    "    json=payload\n",
    ")\n",
    "\n",
    "result = response.json()\n",
    "print(result['output'][0]['text'])\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\"\"\\n# cURL Example\n",
    "curl -X POST \"{workspace_url}/serving-endpoints/{ENDPOINT_NAME}/invocations\" \\\\\n",
    "  -H \"Authorization: Bearer YOUR_DATABRICKS_TOKEN\" \\\\\n",
    "  -H \"Content-Type: application/json\" \\\\\n",
    "  -d '{{\n",
    "    \"input\": [\n",
    "      {{\"role\": \"user\", \"content\": \"What products are at risk for overstock?\"}}\n",
    "    ]\n",
    "  }}'\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Summary\n",
    "\n",
    "Review the deployment status and next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DEPLOYMENT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n‚úÖ Endpoint: {ENDPOINT_NAME}\")\n",
    "print(f\"‚úÖ Model: {UC_MODEL_NAME}\")\n",
    "print(f\"‚úÖ Version: {MODEL_VERSION}\")\n",
    "print(f\"‚úÖ State: {endpoint.state.ready}\")\n",
    "print(f\"‚úÖ Workload: {WORKLOAD_TYPE} {WORKLOAD_SIZE}\")\n",
    "print(f\"‚úÖ Scale to Zero: {SCALE_TO_ZERO}\")\n",
    "\n",
    "print(f\"\\nüìä Test Results:\")\n",
    "print(f\"  ‚úÖ Single domain queries\")\n",
    "print(f\"  ‚úÖ Multi-domain queries\")\n",
    "print(f\"  ‚úÖ Conversation context\")\n",
    "print(f\"  ‚úÖ Performance validation\")\n",
    "\n",
    "print(f\"\\nüîó Endpoint URL: {workspace_url}/ml/endpoints/{ENDPOINT_NAME}\")\n",
    "print(f\"\\nüéØ Scoring URI: {workspace_url}/serving-endpoints/{ENDPOINT_NAME}/invocations\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Deployment successful! Agent is ready for production use.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "**WARNING**: Only run this if you want to delete the endpoint!\n",
    "\n",
    "Uncomment and run to delete the serving endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è UNCOMMENT TO DELETE ENDPOINT\n",
    "# print(f\"Deleting endpoint '{ENDPOINT_NAME}'...\")\n",
    "# w.serving_endpoints.delete(ENDPOINT_NAME)\n",
    "# print(f\"‚úÖ Endpoint deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that your agent is deployed:\n",
    "\n",
    "### 1. **Integration**\n",
    "- Integrate endpoint into applications using the examples above\n",
    "- Use Databricks SDK or REST API\n",
    "- Authentication via Databricks personal access token\n",
    "\n",
    "### 2. **Monitoring**\n",
    "- Monitor endpoint metrics in Databricks UI: `/ml/endpoints/{ENDPOINT_NAME}`\n",
    "- Track request latency, throughput, and errors\n",
    "- Set up alerts for performance degradation\n",
    "\n",
    "### 3. **Scaling**\n",
    "- **Current**: CPU Small (0-4 concurrent requests)\n",
    "- **Medium**: 8-16 concurrent requests\n",
    "- **Large**: 16-64 concurrent requests\n",
    "- Update endpoint configuration as load increases\n",
    "\n",
    "### 4. **Model Versioning**\n",
    "- Test new versions in Unity Catalog\n",
    "- Use aliases for staged rollouts:\n",
    "  - `challenger` ‚Üí testing\n",
    "  - `staging` ‚Üí pre-production\n",
    "  - `champion` ‚Üí production\n",
    "- Update endpoint to new version when ready\n",
    "\n",
    "### 5. **Cost Optimization**\n",
    "- Scale-to-zero enabled (endpoint scales down when idle)\n",
    "- Monitor usage patterns\n",
    "- Adjust workload size based on actual traffic\n",
    "\n",
    "### 6. **Governance**\n",
    "- Model registered in Unity Catalog\n",
    "- Genie Space permissions automatically enforced\n",
    "- Audit logs available in Databricks\n",
    "- Version history tracked in UC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
