{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d344776-3cfc-4f6e-b036-b4496ee8e226",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 03: Test Multi-Agent System with Genie\n",
    "\n",
    "Comprehensive testing of the agent against all functional requirements.\n",
    "\n",
    "**Test Scenarios**:\n",
    "1. Single-domain queries (FR-001, FR-003)\n",
    "2. Multi-domain queries (FR-005, FR-006)\n",
    "3. Context-aware follow-ups (FR-011)\n",
    "4. Proactive suggestions (FR-013)\n",
    "5. Error handling (FR-008)\n",
    "6. Performance (FR-012)\n",
    "\n",
    "**Model Source**: Unity Catalog (`juan_dev.genai.retail_multi_genie_agent`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7da39a5-477a-45a1-b82b-7ce6db72277b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fd9afa0-84f8-4748-bf75-acf4086de281",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade mlflow databricks-langchain langgraph langchain-core\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6faa4f3-63f7-4cd7-8027-c385c988c0a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports successful\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "print(\"✅ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3777903-71b0-4cff-96e3-51ebd6d7435d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Agent from Unity Catalog\n",
    "\n",
    "Load the agent from Unity Catalog using one of these methods:\n",
    "- **Version number**: `models:/catalog.schema.model/1`\n",
    "- **Alias**: `models:/catalog.schema.model@champion`\n",
    "- **Latest version**: `models:/catalog.schema.model/latest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db648ba8-03e1-40e6-b065-b214cf664898",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agent import AGENT\n",
    "\n",
    "# Unity Catalog model (3-level namespace)\n",
    "UC_MODEL_NAME = \"juan_dev.genai.retail_multi_genie_agent\"\n",
    "\n",
    "# Choose loading method:\n",
    "# Option 1: Load latest version\n",
    "# model_uri = f\"models:/{UC_MODEL_NAME}/latest\"\n",
    "\n",
    "# Option 2: Load specific version (uncomment to use)\n",
    "# model_version = \"1\"\n",
    "# model_uri = f\"models:/{UC_MODEL_NAME}/{model_version}\"\n",
    "\n",
    "# Option 3: Load by alias (uncomment to use)\n",
    "model_alias = \"champion\"  # or \"staging\", \"production\", etc.\n",
    "model_uri = f\"models:/{UC_MODEL_NAME}@{model_alias}\"\n",
    "print(f\"Loading agent from Unity Catalog: {model_uri}\")\n",
    "\n",
    "AGENT = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "print(f\"✅ Agent loaded successfully from Unity Catalog\")\n",
    "print(f\"   Model: {UC_MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c12daba7-b4ac-4bf3-9fce-cc281be8093a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de237e67-10fb-4e46-be42-d2a448e44c34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def query_agent(query: str, conversation_history: list = None) -> dict:\n",
    "    \"\"\"Query agent and return result\"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    messages = conversation_history or []\n",
    "    messages.append({\"role\": \"user\", \"content\": query})\n",
    "    \n",
    "    # Create input matching the input_example format from logging\n",
    "    input_data = {\n",
    "        \"input\": messages\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Try calling predict with the dict directly first\n",
    "    try:\n",
    "        response = AGENT.predict(input_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Direct dict call failed: {e}\")\n",
    "        # Fall back to DataFrame\n",
    "        input_df = pd.DataFrame([input_data])\n",
    "        response = AGENT.predict(input_df)\n",
    "    \n",
    "    elapsed_ms = (time.time() - start_time) * 1000\n",
    "    \n",
    "    # Extract response from PyFunc output\n",
    "    # Response format from ResponsesAgent: {output: [{text: \"...\", id: \"...\"}], ...}\n",
    "    if isinstance(response, pd.DataFrame):\n",
    "        output = response.iloc[0]['output']\n",
    "    elif isinstance(response, dict):\n",
    "        output = response.get('output', response)\n",
    "    else:\n",
    "        output = response\n",
    "    \n",
    "    # Handle different output formats\n",
    "    if isinstance(output, list) and len(output) > 0:\n",
    "        if isinstance(output[0], dict):\n",
    "            response_text = output[0].get('text', str(output[0]))\n",
    "        else:\n",
    "            response_text = str(output[0])\n",
    "    elif isinstance(output, dict):\n",
    "        response_text = output.get('text', str(output))\n",
    "    else:\n",
    "        response_text = str(output)\n",
    "    \n",
    "    # Add assistant response to conversation\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response_text})\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"response\": response_text,\n",
    "        \"messages\": messages,\n",
    "        \"elapsed_ms\": elapsed_ms\n",
    "    }\n",
    "\n",
    "def print_result(result: dict):\n",
    "    \"\"\"Pretty print result\"\"\"\n",
    "    print(f\"\\nQuery: {result['query']}\")\n",
    "    print(f\"Response: {result['response']}\")\n",
    "    print(f\"Time: {result['elapsed_ms']:.0f}ms\")\n",
    "\n",
    "print(\"✅ Helper functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc8decdf-da2e-4ca2-a436-d1ac3bc35266",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test 1: Single-Domain Query (FR-001, FR-003)\n",
    "\n",
    "Test basic inventory query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adc74a8d-b068-4a7b-93b8-ccc93f33e8f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = query_agent(\"What products are at risk for overstock?\")\n",
    "print_result(result)\n",
    "\n",
    "# Validations\n",
    "assert result['response'], \"Should have response\"\n",
    "assert result['elapsed_ms'] < 90000, \"Should complete within 90s (Genie timeout)\"\n",
    "assert \"inventory\" in result['response'].lower() or \"overstock\" in result['response'].lower(), \"Should address inventory\"\n",
    "\n",
    "print(\"\\n✅ Test 1 PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78e330df-b9dd-46d5-b3b6-426d68dc886d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test 2: Multi-Domain Query (FR-005, FR-006)\n",
    "\n",
    "Test query spanning customer behavior and inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "099319fb-d9b6-4598-b445-7ccbbe7f4329",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = query_agent(\n",
    "    \"What products are frequently abandoned in carts and do we have inventory issues with those items?\"\n",
    ")\n",
    "print_result(result)\n",
    "\n",
    "# Validations\n",
    "assert result['response'], \"Should have response\"\n",
    "assert result['elapsed_ms'] < 90000, \"Should complete within 90s\"\n",
    "\n",
    "# Check for both domains being addressed\n",
    "response_lower = result['response'].lower()\n",
    "has_customer_behavior = any(keyword in response_lower for keyword in [\"abandon\", \"cart\", \"customer\"])\n",
    "has_inventory = any(keyword in response_lower for keyword in [\"inventory\", \"stock\", \"overstock\", \"stockout\"])\n",
    "\n",
    "print(f\"\\nDomain coverage:\")\n",
    "print(f\"  Customer Behavior: {'✅' if has_customer_behavior else '❌'}\")\n",
    "print(f\"  Inventory: {'✅' if has_inventory else '❌'}\")\n",
    "\n",
    "assert has_customer_behavior or has_inventory, \"Should address at least one domain\"\n",
    "\n",
    "print(\"\\n✅ Test 2 PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39681bb8-19e0-4331-bad5-3a15e094b71c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test 3: Context-Aware Follow-Up (FR-011)\n",
    "\n",
    "Test conversation history and context understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fad3ee8-ef84-4566-a60f-90af402868ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# First query\n",
    "result1 = query_agent(\"What are the top customers by purchase amount?\")\n",
    "print_result(result1)\n",
    "\n",
    "# Follow-up using context\n",
    "conversation_history = result1['messages']\n",
    "result2 = query_agent(\"What products do they purchase most frequently?\", conversation_history)\n",
    "print_result(result2)\n",
    "\n",
    "# Validations\n",
    "assert result2['response'], \"Should have follow-up response\"\n",
    "assert len(conversation_history) >= 4, \"Should maintain conversation history\"\n",
    "\n",
    "print(f\"\\nConversation length: {len(conversation_history)} messages\")\n",
    "print(\"\\n✅ Test 3 PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dedbc7bb-e4b1-4e68-9a35-fcd8a370270a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test 4: Error Handling (FR-008)\n",
    "\n",
    "Test graceful handling of out-of-scope queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "173fc997-4b57-4134-b2cd-96e14968770e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = query_agent(\"What is the weather forecast for next week?\")\n",
    "print_result(result)\n",
    "\n",
    "# Validations\n",
    "assert result['response'], \"Should provide response\"\n",
    "# Agent should politely explain it can't answer weather questions or provide guidance\n",
    "\n",
    "print(\"\\n✅ Test 4 PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d11c0400-daf3-473f-b26e-4a7c797fbf6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test 5: Customer Behavior Domain\n",
    "\n",
    "Test specific customer behavior queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04f9467b-b60b-4741-843a-814b65d1fbe3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customer_queries = [\n",
    "    \"What is the cart abandonment rate?\",\n",
    "    \"Which customer segments have the highest purchase frequency?\",\n",
    "    \"Show me top products by cart abandonment\"\n",
    "]\n",
    "\n",
    "for query in customer_queries:\n",
    "    result = query_agent(query)\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(f\"Time: {result['elapsed_ms']:.0f}ms\")\n",
    "    print(f\"Response preview: {result['response'][:200]}...\")\n",
    "    assert result['response'], f\"Should have response for: {query}\"\n",
    "\n",
    "print(\"\\n✅ Test 5 PASSED - Customer behavior queries working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f85fa1b-d4e3-440b-9e92-e5aec05bd808",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test 6: Inventory Domain\n",
    "\n",
    "Test specific inventory queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b162cb74-0182-4e77-9d7a-789371088364",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "inventory_queries = [\n",
    "    \"What items are at risk of stockout?\",\n",
    "    \"Show me products with high inventory turnover\",\n",
    "    \"Which products have overstock issues?\"\n",
    "]\n",
    "\n",
    "for query in inventory_queries:\n",
    "    result = query_agent(query)\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(f\"Time: {result['elapsed_ms']:.0f}ms\")\n",
    "    print(f\"Response preview: {result['response'][:200]}...\")\n",
    "    assert result['response'], f\"Should have response for: {query}\"\n",
    "\n",
    "print(\"\\n✅ Test 6 PASSED - Inventory queries working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "456d09b4-d9a5-45c0-9bda-fe0ded191b31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test 7: Performance (FR-012)\n",
    "\n",
    "Verify complex queries complete within acceptable time (90s for Genie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfa1afcf-dd0e-44d6-91e2-17f72f7d7871",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "complex_queries = [\n",
    "    \"Analyze cart abandonment patterns and correlate with inventory stockouts\",\n",
    "    \"What products have high cart abandonment and low inventory?\",\n",
    "    \"Show customer segments most affected by inventory constraints\"\n",
    "]\n",
    "\n",
    "for query in complex_queries:\n",
    "    result = query_agent(query)\n",
    "    print(f\"\\nQuery: {query[:60]}...\")\n",
    "    print(f\"Time: {result['elapsed_ms']:.0f}ms\")\n",
    "    assert result['elapsed_ms'] < 90000, f\"Query exceeded 90s: {result['elapsed_ms']}ms\"\n",
    "\n",
    "print(\"\\n✅ Test 7 PASSED - All queries under 90s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecedc972-1231-4314-8990-c312dc1f8280",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test Summary\n",
    "\n",
    "Run this cell to see overall test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4dc5ad6-bce0-44aa-921e-9ac4b06d391c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TEST SUMMARY - Multi-Agent Genie System\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {UC_MODEL_NAME}\")\n",
    "print(f\"Source: {model_uri}\")\n",
    "print(\"=\"*60)\n",
    "print(\"✅ Test 1: Single-domain queries (FR-001, FR-003)\")\n",
    "print(\"✅ Test 2: Multi-domain queries (FR-005, FR-006)\")\n",
    "print(\"✅ Test 3: Context-aware follow-ups (FR-011)\")\n",
    "print(\"✅ Test 4: Error handling (FR-008)\")\n",
    "print(\"✅ Test 5: Customer behavior domain queries\")\n",
    "print(\"✅ Test 6: Inventory domain queries\")\n",
    "print(\"✅ Test 7: Performance under 90s (FR-012)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n\uD83C\uDF89 All tests completed!\")\n",
    "print(\"\\nAgent is ready for production deployment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca921083-1606-4217-a36f-cabd215a6c4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Set Model Alias (Optional)\n",
    "\n",
    "Set an alias like `champion`, `staging`, or `production` for easier model management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec4825cd-a437-4be1-99ab-4d3f9525e490",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Get the latest version number\n",
    "latest_version = client.get_latest_versions(UC_MODEL_NAME, stages=[\"None\"])[0].version\n",
    "\n",
    "# Set alias (uncomment to use)\n",
    "# alias_name = \"champion\"  # or \"staging\", \"production\", etc.\n",
    "# client.set_registered_model_alias(UC_MODEL_NAME, alias_name, latest_version)\n",
    "# print(f\"✅ Set alias '{alias_name}' to version {latest_version}\")\n",
    "# print(f\"   Load with: models:/{UC_MODEL_NAME}@{alias_name}\")\n",
    "\n",
    "print(f\"Latest version: {latest_version}\")\n",
    "print(f\"\\nAvailable aliases:\")\n",
    "model_details = client.get_registered_model(UC_MODEL_NAME)\n",
    "if hasattr(model_details, 'aliases') and model_details.aliases:\n",
    "    for alias, version in model_details.aliases.items():\n",
    "        print(f\"  - {alias} → version {version}\")\n",
    "else:\n",
    "    print(\"  (no aliases set yet)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91a05871-6c71-41e3-bf7c-b664344bcf53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "1. ✅ Tests passed - agent is working correctly\n",
    "2. Set model alias (e.g., `champion`) for production tracking\n",
    "3. Deploy to Model Serving endpoint:\n",
    "   - Use Unity Catalog model: `juan_dev.genai.retail_multi_genie_agent`\n",
    "   - Enable auto-scaling and authentication passthrough\n",
    "4. Create evaluation dataset for MLflow evaluation\n",
    "5. Set up monitoring and alerting"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "03-test-agent",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}