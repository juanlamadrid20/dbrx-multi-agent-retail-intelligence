{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02: Create Multi-Agent System with Genie Agents\n",
    "\n",
    "Create a supervisor-based multi-agent system using LangGraph and Databricks Genie agents.\n",
    "\n",
    "**Pattern**: Based on [Databricks LangGraph Multi-Agent Genie Guide](https://docs.databricks.com/aws/en/generative-ai/agent-framework/multi-agent-genie)\n",
    "\n",
    "**Key Features**:\n",
    "- Supervisor agent pattern coordinating multiple Genie agents\n",
    "- GenieAgent for accessing Genie Spaces (no custom UC Functions needed)\n",
    "- Automatic authentication via GenieAgent\n",
    "- ResponsesAgent wrapper for MLflow compatibility\n",
    "- Streaming support via predict_stream()\n",
    "\n",
    "**Architecture**:\n",
    "```\n",
    "Supervisor Agent\n",
    "  ├─ Customer Behavior Genie Agent (space: 01f0b7572b3a185d9f69cd89bc4c7579)\n",
    "  └─ Inventory Management Genie Agent (space: 01f09cdef66116e5940de4b384623be9)\n",
    "```\n",
    "\n",
    "**Prerequisites**: None! GenieAgent handles authentication automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade mlflow databricks-langchain langgraph langchain-core\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Genie Space Access\n",
    "\n",
    "**IMPORTANT**: Before creating the agent, verify you have permissions to access the Genie spaces. see notebook test-genie-access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent Module (agent.py)\n",
    "\n",
    "Using `%%writefile` to create standalone agent file with GenieAgent supervisor pattern.\n",
    "\n",
    "**Note**: Only run this after verifying Genie space access above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    os.remove('agent.py')\n",
    "except Exception as e:\n",
    "    print(f\"Error removing 'agent.py': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from typing import TypedDict, Annotated, Sequence, Any, Optional\n",
    "from langchain_core.messages import AnyMessage, BaseMessage, AIMessage, HumanMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END\n",
    "from databricks_langchain import ChatDatabricks, GenieAgent\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import ResponsesAgentRequest, ResponsesAgentResponse, create_text_output_item\n",
    "\n",
    "# Import modular configuration\n",
    "from config.agent_config import AGENT_CONFIG, DOMAINS\n",
    "from config.prompts import SYSTEM_PROMPT\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# State Management\n",
    "# ============================================================================\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"Agent state with type annotations.\"\"\"\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Create Genie Agents (Lazy Loading)\n",
    "# ============================================================================\n",
    "\n",
    "# Store Genie agents globally to avoid re-initialization\n",
    "_genie_agents = None\n",
    "\n",
    "def get_genie_agents():\n",
    "    \"\"\"Lazy-load GenieAgent instances for each domain.\"\"\"\n",
    "    global _genie_agents\n",
    "    \n",
    "    if _genie_agents is None:\n",
    "        _genie_agents = {}\n",
    "        \n",
    "        # Customer Behavior Genie Agent\n",
    "        _genie_agents[\"customer_behavior\"] = GenieAgent(\n",
    "            genie_space_id=DOMAINS[\"customer_behavior\"].genie_space_id,\n",
    "            genie_agent_name=DOMAINS[\"customer_behavior\"].name,\n",
    "            description=DOMAINS[\"customer_behavior\"].description,\n",
    "        )\n",
    "        \n",
    "        # Inventory Management Genie Agent\n",
    "        _genie_agents[\"inventory\"] = GenieAgent(\n",
    "            genie_space_id=DOMAINS[\"inventory\"].genie_space_id,\n",
    "            genie_agent_name=DOMAINS[\"inventory\"].name,\n",
    "            description=DOMAINS[\"inventory\"].description,\n",
    "        )\n",
    "    \n",
    "    return _genie_agents\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Supervisor Agent\n",
    "# ============================================================================\n",
    "\n",
    "def create_supervisor_agent(llm):\n",
    "    \"\"\"Create supervisor agent that routes queries to Genie agents.\"\"\"\n",
    "    \n",
    "    def supervisor_node(state: AgentState):\n",
    "        \"\"\"Supervisor decides which agent(s) to call.\"\"\"\n",
    "        # Lazy-load Genie agents here (not at import time)\n",
    "        genie_agents = get_genie_agents()\n",
    "\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "\n",
    "        # Simple keyword-based routing\n",
    "        query = last_message.content.lower()\n",
    "\n",
    "        responses = []\n",
    "\n",
    "        # Route to customer behavior agent\n",
    "        if any(keyword in query for keyword in [\"cart\", \"abandon\", \"customer\", \"behavior\", \"segment\", \"purchase\"]):\n",
    "            try:\n",
    "                cb_response = genie_agents[\"customer_behavior\"].invoke({\"messages\": [last_message]})\n",
    "                # Extract the response message properly\n",
    "                if cb_response and \"messages\" in cb_response and len(cb_response[\"messages\"]) > 0:\n",
    "                    response_msg = cb_response[\"messages\"][-1]\n",
    "                    content = response_msg.content if hasattr(response_msg, 'content') else str(response_msg)\n",
    "                    responses.append(f\"[Customer Behavior]\\n{content}\")\n",
    "            except Exception as e:\n",
    "                responses.append(f\"[Customer Behavior]\\n[Error]: {str(e)}\")\n",
    "\n",
    "        # Route to inventory agent\n",
    "        if any(keyword in query for keyword in [\"inventory\", \"stock\", \"overstock\", \"stockout\", \"supply\"]):\n",
    "            try:\n",
    "                inv_response = genie_agents[\"inventory\"].invoke({\"messages\": [last_message]})\n",
    "                # Extract the response message properly\n",
    "                if inv_response and \"messages\" in inv_response and len(inv_response[\"messages\"]) > 0:\n",
    "                    response_msg = inv_response[\"messages\"][-1]\n",
    "                    content = response_msg.content if hasattr(response_msg, 'content') else str(response_msg)\n",
    "                    responses.append(f\"[Inventory]\\n{content}\")\n",
    "            except Exception as e:\n",
    "                responses.append(f\"[Inventory]\\n[Error]: {str(e)}\")\n",
    "\n",
    "        # If no specific routing, provide guidance\n",
    "        if not responses:\n",
    "            response_text = \"I can help you with:\\n- Customer behavior analysis (cart abandonment, segmentation, purchase patterns)\\n- Inventory management (stock levels, stockouts, overstock)\\n\\nPlease ask a question related to these topics.\"\n",
    "        else:\n",
    "            response_text = \"\\n\\n\".join(responses)\n",
    "\n",
    "        # Return properly formatted state update\n",
    "        return {\"messages\": [AIMessage(content=response_text)]}\n",
    "    \n",
    "    # Build simple graph with supervisor node\n",
    "    workflow = StateGraph(AgentState)\n",
    "    workflow.add_node(\"supervisor\", supervisor_node)\n",
    "    workflow.set_entry_point(\"supervisor\")\n",
    "    workflow.add_edge(\"supervisor\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ResponsesAgent Wrapper\n",
    "# ============================================================================\n",
    "\n",
    "class MultiGenieResponsesAgent(ResponsesAgent):\n",
    "    \"\"\"ResponsesAgent wrapper for multi-Genie agent system.\"\"\"\n",
    "    \n",
    "    def __init__(self, agent_graph):\n",
    "        self.agent = agent_graph\n",
    "    \n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        \"\"\"Synchronous prediction.\"\"\"\n",
    "        import uuid\n",
    "        \n",
    "        # Convert request messages to LangChain format\n",
    "        messages = []\n",
    "        for msg in request.input:\n",
    "            msg_dict = msg.model_dump() if hasattr(msg, 'model_dump') else msg\n",
    "            role = msg_dict.get(\"role\", \"user\")\n",
    "            content = msg_dict.get(\"content\", \"\")\n",
    "            \n",
    "            if role == \"user\":\n",
    "                messages.append(HumanMessage(content=content))\n",
    "            elif role == \"assistant\":\n",
    "                messages.append(AIMessage(content=content))\n",
    "        \n",
    "        # Invoke agent with properly formatted state (just messages, no custom fields)\n",
    "        result = self.agent.invoke({\"messages\": messages}, config={\"configurable\": {}})\n",
    "        \n",
    "        # Extract response\n",
    "        final_message = result[\"messages\"][-1]\n",
    "        \n",
    "        # Use helper method to create properly validated output with unique ID\n",
    "        return ResponsesAgentResponse(\n",
    "            output=[create_text_output_item(\n",
    "                text=final_message.content,\n",
    "                id=f\"msg_{uuid.uuid4().hex[:8]}\"\n",
    "            )],\n",
    "            custom_outputs=request.custom_inputs\n",
    "        )\n",
    "    \n",
    "    def predict_stream(self, request: ResponsesAgentRequest):\n",
    "        \"\"\"Streaming prediction.\"\"\"\n",
    "        from mlflow.types.responses import output_to_responses_items_stream\n",
    "        \n",
    "        # Convert request messages to LangChain format\n",
    "        messages = []\n",
    "        for msg in request.input:\n",
    "            msg_dict = msg.model_dump() if hasattr(msg, 'model_dump') else msg\n",
    "            role = msg_dict.get(\"role\", \"user\")\n",
    "            content = msg_dict.get(\"content\", \"\")\n",
    "            \n",
    "            if role == \"user\":\n",
    "                messages.append(HumanMessage(content=content))\n",
    "            elif role == \"assistant\":\n",
    "                messages.append(AIMessage(content=content))\n",
    "        \n",
    "        # Stream agent execution\n",
    "        for event in self.agent.stream({\"messages\": messages}, stream_mode=[\"updates\", \"messages\"], config={\"configurable\": {}}):\n",
    "            if event[0] == \"updates\":\n",
    "                for node_data in event[1].values():\n",
    "                    if len(node_data.get(\"messages\", [])) > 0:\n",
    "                        yield from output_to_responses_items_stream(node_data[\"messages\"])\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Agent Initialization\n",
    "# ============================================================================\n",
    "\n",
    "def initialize_agent():\n",
    "    \"\"\"Initialize multi-agent system with modular configuration.\"\"\"\n",
    "    # Initialize LLM from config\n",
    "    llm = ChatDatabricks(\n",
    "        endpoint=AGENT_CONFIG[\"model_endpoint\"],\n",
    "        temperature=AGENT_CONFIG[\"temperature\"],\n",
    "        max_tokens=AGENT_CONFIG[\"max_tokens\"]\n",
    "    )\n",
    "    \n",
    "    # Create supervisor agent (Genie agents are lazy-loaded)\n",
    "    agent_graph = create_supervisor_agent(llm)\n",
    "    \n",
    "    # Wrap in ResponsesAgent\n",
    "    return MultiGenieResponsesAgent(agent_graph)\n",
    "\n",
    "\n",
    "# Create agent instance for MLflow\n",
    "AGENT = initialize_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart Python\n",
    "\n",
    "After creating agent.py, restart Python to load the module.\n",
    "\n",
    "**Note**: Run this cell, then proceed to test the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Agent - Single Domain Query\n",
    "\n",
    "Test the agent with a simple inventory query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import AGENT\n",
    "from mlflow.types.responses import ResponsesAgentRequest\n",
    "\n",
    "# Test query - should route to inventory agent\n",
    "test_query = \"What 5 products are at risk for overstock?\"\n",
    "\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "\n",
    "# Create request with message dict\n",
    "request = ResponsesAgentRequest(\n",
    "    input=[{\"role\": \"user\", \"content\": test_query}]\n",
    ")\n",
    "\n",
    "# Test synchronous prediction\n",
    "response = AGENT.predict(request)\n",
    "\n",
    "print(f\"Response:\\n{response.output[0]}\")\n",
    "print(f\"\\n✅ Agent test PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Agent - Multi-Domain Query with Streaming\n",
    "\n",
    "Test the agent with a query that should route to both customer behavior and inventory agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.types.responses import ResponsesAgentRequest\n",
    "\n",
    "# Test multi-domain query - should route to both agents\n",
    "test_query = \"What products are frequently abandoned in carts and do we have inventory issues with those items?\"\n",
    "\n",
    "# Create request\n",
    "request = ResponsesAgentRequest(\n",
    "    input=[{\"role\": \"user\", \"content\": test_query}]\n",
    ")\n",
    "\n",
    "print(f\"Streaming response for: {test_query}\\n\")\n",
    "print(\"Response: \")\n",
    "\n",
    "for event in AGENT.predict_stream(request):\n",
    "    if event.type == \"response.output_item.done\":\n",
    "        print(event.item.get('text', ''), end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\\n✅ Streaming test PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Agent to MLflow\n",
    "\n",
    "Register the agent using `mlflow.models.set_model()` (Databricks pattern)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from mlflow.models.resources import DatabricksGenieSpace\n",
    "from config.agent_config import AGENT_CONFIG, DOMAINS\n",
    "\n",
    "# Set MLflow experiment\n",
    "username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "experiment_name = f\"/Users/{username}/ml/experiments/multi-genie-agent\"\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "print(f\"MLflow experiment: {experiment_name}\\n\")\n",
    "\n",
    "# Enable autolog for trace capture\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "# Prepare resources for automatic authentication passthrough\n",
    "resources = []\n",
    "\n",
    "# Add Genie spaces (GenieAgent handles authentication automatically)\n",
    "for domain in DOMAINS.values():\n",
    "    resources.append(DatabricksGenieSpace(genie_space_id=domain.genie_space_id))\n",
    "\n",
    "print(f\"Declaring {len(resources)} Genie Space resources for automatic auth passthrough:\")\n",
    "for resource in resources:\n",
    "    print(f\"  - {resource}\")\n",
    "print()\n",
    "\n",
    "# Log agent\n",
    "with mlflow.start_run(run_name=\"multi-genie-supervisor-agent\") as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_params({\n",
    "        \"model_endpoint\": AGENT_CONFIG[\"model_endpoint\"],\n",
    "        \"temperature\": AGENT_CONFIG[\"temperature\"],\n",
    "        \"max_tokens\": AGENT_CONFIG[\"max_tokens\"],\n",
    "        \"timeout_seconds\": AGENT_CONFIG[\"timeout_seconds\"],\n",
    "        \"agent_type\": \"multi_genie_supervisor\"\n",
    "    })\n",
    "    \n",
    "    # Log Genie space IDs as tags\n",
    "    mlflow.set_tags({\n",
    "        f\"genie_space_{domain.name}\": domain.genie_space_id\n",
    "        for domain in DOMAINS.values()\n",
    "    })\n",
    "    \n",
    "    # Import and log agent with automatic authentication passthrough\n",
    "    from agent import AGENT\n",
    "    \n",
    "    # Create proper input example for ResponsesAgent\n",
    "    input_example = {\n",
    "        \"input\": [\n",
    "            {\"role\": \"user\", \"content\": \"What products are at risk for overstock?\"}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=AGENT,\n",
    "        resources=resources,\n",
    "        input_example=input_example\n",
    "    )\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    print(f\"✅ Multi-agent system logged to MLflow with automatic authentication passthrough\")\n",
    "    print(f\"Run ID: {run_id}\")\n",
    "    print(f\"Model URI: {logged_agent_info.model_uri}\")\n",
    "    print(f\"Experiment: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify MLflow Registration\n",
    "\n",
    "Check that the agent is properly registered and ready for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current run\n",
    "current_run = mlflow.get_run(run_id)\n",
    "\n",
    "print(\"Registered Multi-Agent System Details:\")\n",
    "print(f\"  Run ID: {current_run.info.run_id}\")\n",
    "print(f\"  Status: {current_run.info.status}\")\n",
    "print(f\"  Agent Type: {current_run.data.params.get('agent_type')}\")\n",
    "print(f\"  Model Endpoint: {current_run.data.params.get('model_endpoint')}\")\n",
    "print(f\"\\n  Genie Spaces:\")\n",
    "for tag_key, tag_value in current_run.data.tags.items():\n",
    "    if tag_key.startswith('genie_space_'):\n",
    "        print(f\"    - {tag_key}: {tag_value}\")\n",
    "\n",
    "print(\"\\n✅ Multi-agent system ready for deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Model to Unity Catalog\n",
    "\n",
    "Register the agent to Unity Catalog for production deployment and governance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Unity Catalog as the model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Define UC model location\n",
    "catalog = \"juan_dev\"\n",
    "schema = \"genai\"\n",
    "model_name = \"retail_multi_genie_agent\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "print(f\"Registering model to Unity Catalog: {UC_MODEL_NAME}\")\n",
    "\n",
    "# Get the model URI from the current run\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "# Register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=model_uri,\n",
    "    name=UC_MODEL_NAME\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Model registered to Unity Catalog!\")\n",
    "print(f\"   Model: {UC_MODEL_NAME}\")\n",
    "print(f\"   Version: {uc_registered_model_info.version}\")\n",
    "print(f\"   Run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify UC Registration\n",
    "\n",
    "Confirm the model is available in Unity Catalog with all resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the registered model from UC\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Get model version details\n",
    "model_version_details = client.get_model_version(\n",
    "    name=UC_MODEL_NAME,\n",
    "    version=uc_registered_model_info.version\n",
    ")\n",
    "\n",
    "print(\"Unity Catalog Model Details:\")\n",
    "print(f\"  Name: {model_version_details.name}\")\n",
    "print(f\"  Version: {model_version_details.version}\")\n",
    "print(f\"  Status: {model_version_details.status}\")\n",
    "print(f\"  Source: {model_version_details.source}\")\n",
    "\n",
    "print(\"\\n✅ Model successfully registered and ready for deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "✅ Multi-agent system created with GenieAgent supervisor pattern, logged to MLflow, and registered to Unity Catalog!\n",
    "\n",
    "**Key Accomplishments:**\n",
    "- GenieAgent for Genie Space access (no custom UC Functions!)\n",
    "- Automatic authentication via GenieAgent (no WorkspaceClient issues)\n",
    "- Supervisor pattern routes queries to appropriate domain agents\n",
    "- Supports multi-domain queries across both Genie spaces\n",
    "- ResponsesAgent wrapper for MLflow compatibility\n",
    "- Streaming support via predict_stream()\n",
    "- **Registered to Unity Catalog for production deployment**\n",
    "\n",
    "**Unity Catalog Model**: `juan_dev.genai.retail_multi_genie_agent`\n",
    "\n",
    "**Next**:\n",
    "1. Open `03-test-agent.ipynb` to run comprehensive tests\n",
    "2. Deploy model to Model Serving endpoint for production use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
