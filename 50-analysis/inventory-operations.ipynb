{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📦 Inventory & Operations Analytics\n",
    "\n",
    "This notebook provides comprehensive inventory management and operations analytics for fashion retail. The queries cover inventory health, supply chain efficiency, location performance, demand planning, and operational KPIs.\n",
    "\n",
    "## 📊 Key Areas Covered:\n",
    "- **Inventory Health & Optimization**\n",
    "- **Supply Chain & Movement Analytics** \n",
    "- **Location Performance & Operations**\n",
    "- **Demand Planning & Forecasting**\n",
    "- **Stockout & Overstock Analysis**\n",
    "- **Financial Inventory Metrics**\n",
    "\n",
    "These queries provide actionable insights for:\n",
    "- Inventory managers optimizing stock levels\n",
    "- Operations teams managing fulfillment\n",
    "- Supply chain analysts tracking efficiency\n",
    "- Financial teams managing inventory investment\n",
    "- Buyers and planners optimizing assortments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 📈 Inventory Health & Stock Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- 1.1 Current Inventory Health Dashboard\n",
    "WITH current_inventory AS (\n",
    "    SELECT \n",
    "        i.product_key,\n",
    "        p.sku,\n",
    "        p.product_name,\n",
    "        p.category_level_1,\n",
    "        p.category_level_2,\n",
    "        p.brand,\n",
    "        p.price_tier,\n",
    "        l.location_type,\n",
    "        l.location_name,\n",
    "        l.region,\n",
    "        i.quantity_on_hand,\n",
    "        i.quantity_available,\n",
    "        i.quantity_reserved,\n",
    "        i.quantity_in_transit,\n",
    "        i.days_of_supply,\n",
    "        i.stock_cover_days,\n",
    "        i.inventory_value_cost,\n",
    "        i.inventory_value_retail,\n",
    "        i.is_stockout,\n",
    "        i.is_overstock,\n",
    "        i.reorder_point,\n",
    "        i.reorder_quantity\n",
    "    FROM juan_dev.retail.gold_inventory_fact i\n",
    "    JOIN juan_dev.retail.gold_product_dim p ON i.product_key = p.product_key\n",
    "    JOIN juan_dev.retail.gold_location_dim l ON i.location_key = l.location_key\n",
    "    WHERE i.date_key = (\n",
    "        SELECT MAX(date_key) \n",
    "        FROM juan_dev.retail.gold_inventory_fact\n",
    "    )\n",
    "    AND p.is_active = true\n",
    "    AND l.is_active = true\n",
    "),\n",
    "inventory_health AS (\n",
    "    SELECT\n",
    "        category_level_1,\n",
    "        category_level_2,\n",
    "        location_type,\n",
    "        region,\n",
    "        COUNT(*) as total_skus,\n",
    "        COUNT(DISTINCT product_key) as unique_products,\n",
    "        \n",
    "        -- Quantity metrics\n",
    "        SUM(quantity_on_hand) as total_units_on_hand,\n",
    "        SUM(quantity_available) as total_available_units,\n",
    "        SUM(quantity_reserved) as total_reserved_units,\n",
    "        SUM(quantity_in_transit) as total_in_transit_units,\n",
    "        \n",
    "        -- Financial metrics\n",
    "        SUM(inventory_value_cost) as total_cost_value,\n",
    "        SUM(inventory_value_retail) as total_retail_value,\n",
    "        SUM(inventory_value_retail) - SUM(inventory_value_cost) as total_markup_value,\n",
    "        \n",
    "        -- Health indicators\n",
    "        SUM(CASE WHEN is_stockout THEN 1 ELSE 0 END) as stockout_count,\n",
    "        SUM(CASE WHEN is_overstock THEN 1 ELSE 0 END) as overstock_count,\n",
    "        SUM(CASE WHEN quantity_available <= reorder_point THEN 1 ELSE 0 END) as reorder_needed_count,\n",
    "        \n",
    "        -- Performance ratios\n",
    "        ROUND(SUM(CASE WHEN is_stockout THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as stockout_rate_pct,\n",
    "        ROUND(SUM(CASE WHEN is_overstock THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as overstock_rate_pct,\n",
    "        ROUND(SUM(quantity_available) * 100.0 / NULLIF(SUM(quantity_on_hand), 0), 2) as availability_rate_pct,\n",
    "        \n",
    "        -- Supply metrics\n",
    "        AVG(days_of_supply) as avg_days_of_supply,\n",
    "        AVG(stock_cover_days) as avg_stock_cover_days\n",
    "    FROM current_inventory\n",
    "    GROUP BY category_level_1, category_level_2, location_type, region\n",
    ")\n",
    "SELECT \n",
    "    category_level_1,\n",
    "    category_level_2,\n",
    "    location_type,\n",
    "    region,\n",
    "    total_skus,\n",
    "    unique_products,\n",
    "    total_units_on_hand,\n",
    "    total_available_units,\n",
    "    ROUND(total_cost_value, 2) as total_cost_value,\n",
    "    ROUND(total_retail_value, 2) as total_retail_value,\n",
    "    ROUND(total_markup_value, 2) as total_markup_value,\n",
    "    stockout_count,\n",
    "    overstock_count,\n",
    "    reorder_needed_count,\n",
    "    stockout_rate_pct,\n",
    "    overstock_rate_pct,\n",
    "    availability_rate_pct,\n",
    "    ROUND(avg_days_of_supply, 1) as avg_days_supply,\n",
    "    ROUND(avg_stock_cover_days, 1) as avg_stock_cover\n",
    "FROM inventory_health\n",
    "ORDER BY total_retail_value DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- 1.2 ABC Analysis for Inventory Classification\n",
    "WITH product_performance AS (\n",
    "    SELECT \n",
    "        p.product_key,\n",
    "        p.sku,\n",
    "        p.product_name,\n",
    "        p.category_level_2,\n",
    "        p.brand,\n",
    "        \n",
    "        -- Sales performance (last 90 days)\n",
    "        COALESCE(SUM(s.net_sales_amount), 0) as total_revenue_90d,\n",
    "        COALESCE(SUM(s.quantity_sold), 0) as total_units_sold_90d,\n",
    "        COALESCE(COUNT(DISTINCT s.date_key), 0) as selling_days,\n",
    "        \n",
    "        -- Current inventory investment\n",
    "        SUM(i.inventory_value_cost) as current_inventory_cost,\n",
    "        SUM(i.inventory_value_retail) as current_inventory_retail,\n",
    "        SUM(i.quantity_on_hand) as total_units_on_hand,\n",
    "        \n",
    "        -- Calculate turnover and velocity\n",
    "        CASE \n",
    "            WHEN SUM(i.inventory_value_cost) > 0 \n",
    "            THEN COALESCE(SUM(s.net_sales_amount), 0) * 365.0 / (90 * SUM(i.inventory_value_cost))\n",
    "            ELSE 0 \n",
    "        END as inventory_turnover_ratio,\n",
    "        \n",
    "        CASE \n",
    "            WHEN SUM(i.quantity_on_hand) > 0 \n",
    "            THEN COALESCE(SUM(s.quantity_sold), 0) * 365.0 / (90 * SUM(i.quantity_on_hand))\n",
    "            ELSE 0 \n",
    "        END as inventory_velocity\n",
    "        \n",
    "    FROM juan_dev.retail.gold_product_dim p\n",
    "    LEFT JOIN juan_dev.retail.gold_sales_fact s \n",
    "        ON p.product_key = s.product_key \n",
    "        AND s.date_key >= (\n",
    "            SELECT date_key \n",
    "            FROM juan_dev.retail.gold_date_dim \n",
    "            WHERE calendar_date = DATE_SUB(CURRENT_DATE, 90)\n",
    "        )\n",
    "        AND s.is_return = false\n",
    "    JOIN juan_dev.retail.gold_inventory_fact i \n",
    "        ON p.product_key = i.product_key\n",
    "        AND i.date_key = (\n",
    "            SELECT MAX(date_key) \n",
    "            FROM juan_dev.retail.gold_inventory_fact\n",
    "        )\n",
    "    WHERE p.is_active = true\n",
    "    GROUP BY p.product_key, p.sku, p.product_name, p.category_level_2, p.brand\n",
    "),\n",
    "revenue_percentiles AS (\n",
    "    SELECT \n",
    "        *,\n",
    "        PERCENT_RANK() OVER (ORDER BY total_revenue_90d DESC) as revenue_percentile,\n",
    "        PERCENT_RANK() OVER (ORDER BY current_inventory_cost DESC) as investment_percentile,\n",
    "        PERCENT_RANK() OVER (ORDER BY inventory_turnover_ratio DESC) as turnover_percentile\n",
    "    FROM product_performance\n",
    "),\n",
    "abc_classification AS (\n",
    "    SELECT \n",
    "        *,\n",
    "        CASE \n",
    "            WHEN revenue_percentile >= 0.8 THEN 'A - High Revenue'\n",
    "            WHEN revenue_percentile >= 0.5 THEN 'B - Medium Revenue' \n",
    "            ELSE 'C - Low Revenue'\n",
    "        END as abc_revenue_class,\n",
    "        \n",
    "        CASE \n",
    "            WHEN turnover_percentile >= 0.8 THEN 'Fast Moving'\n",
    "            WHEN turnover_percentile >= 0.5 THEN 'Medium Moving'\n",
    "            ELSE 'Slow Moving'\n",
    "        END as velocity_class,\n",
    "        \n",
    "        CASE \n",
    "            WHEN investment_percentile >= 0.8 THEN 'High Investment'\n",
    "            WHEN investment_percentile >= 0.5 THEN 'Medium Investment'\n",
    "            ELSE 'Low Investment'\n",
    "        END as investment_class\n",
    "    FROM revenue_percentiles\n",
    ")\n",
    "SELECT \n",
    "    abc_revenue_class,\n",
    "    velocity_class,\n",
    "    investment_class,\n",
    "    COUNT(*) as product_count,\n",
    "    SUM(total_revenue_90d) as total_revenue,\n",
    "    SUM(current_inventory_cost) as total_investment,\n",
    "    SUM(total_units_sold_90d) as total_units_sold,\n",
    "    SUM(total_units_on_hand) as total_units_on_hand,\n",
    "    AVG(inventory_turnover_ratio) as avg_turnover_ratio,\n",
    "    AVG(inventory_velocity) as avg_velocity,\n",
    "    \n",
    "    -- Portfolio percentages\n",
    "    ROUND(SUM(total_revenue_90d) * 100.0 / SUM(SUM(total_revenue_90d)) OVER (), 2) as revenue_share_pct,\n",
    "    ROUND(SUM(current_inventory_cost) * 100.0 / SUM(SUM(current_inventory_cost)) OVER (), 2) as investment_share_pct\n",
    "    \n",
    "FROM abc_classification\n",
    "GROUP BY abc_revenue_class, velocity_class, investment_class\n",
    "ORDER BY total_revenue DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 🚚 Supply Chain & Movement Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- 2.1 Inventory Movement Flow Analysis\n",
    "WITH movement_summary AS (\n",
    "    SELECT \n",
    "        im.movement_type,\n",
    "        im.movement_reason,\n",
    "        d.fiscal_quarter,\n",
    "        d.month_name,\n",
    "        \n",
    "        -- Location context\n",
    "        l_from.location_type as from_location_type,\n",
    "        l_from.region as from_region,\n",
    "        l_to.location_type as to_location_type,\n",
    "        l_to.region as to_region,\n",
    "        \n",
    "        -- Product context\n",
    "        p.category_level_1,\n",
    "        p.category_level_2,\n",
    "        p.price_tier,\n",
    "        \n",
    "        -- Movement metrics\n",
    "        COUNT(*) as movement_count,\n",
    "        SUM(im.quantity) as total_units_moved,\n",
    "        SUM(im.unit_cost * im.quantity) as total_movement_value,\n",
    "        AVG(im.quantity) as avg_movement_size,\n",
    "        \n",
    "        -- Timing metrics  \n",
    "        AVG(DATEDIFF(im.completion_date, im.request_date)) as avg_processing_days\n",
    "        \n",
    "    FROM juan_dev.retail.gold_inventory_movement_fact im\n",
    "    JOIN juan_dev.retail.gold_date_dim d ON im.date_key = d.date_key\n",
    "    JOIN juan_dev.retail.gold_product_dim p ON im.product_key = p.product_key\n",
    "    LEFT JOIN juan_dev.retail.gold_location_dim l_from ON im.from_location_key = l_from.location_key\n",
    "    LEFT JOIN juan_dev.retail.gold_location_dim l_to ON im.to_location_key = l_to.location_key\n",
    "    WHERE d.calendar_date >= DATE_SUB(CURRENT_DATE, 90)\n",
    "    GROUP BY \n",
    "        im.movement_type, im.movement_reason, d.fiscal_quarter, d.month_name,\n",
    "        l_from.location_type, l_from.region, l_to.location_type, l_to.region,\n",
    "        p.category_level_1, p.category_level_2, p.price_tier\n",
    ")\n",
    "SELECT \n",
    "    movement_type,\n",
    "    movement_reason,\n",
    "    CONCAT(COALESCE(from_location_type, 'External'), ' → ', COALESCE(to_location_type, 'External')) as movement_flow,\n",
    "    CONCAT(COALESCE(from_region, 'External'), ' → ', COALESCE(to_region, 'External')) as region_flow,\n",
    "    category_level_1,\n",
    "    price_tier,\n",
    "    \n",
    "    SUM(movement_count) as total_movements,\n",
    "    SUM(total_units_moved) as total_units,\n",
    "    ROUND(SUM(total_movement_value), 2) as total_value,\n",
    "    ROUND(AVG(avg_movement_size), 1) as avg_units_per_movement,\n",
    "    ROUND(AVG(avg_processing_days), 1) as avg_processing_days,\n",
    "    \n",
    "    -- Movement efficiency\n",
    "    ROUND(SUM(total_units_moved) / NULLIF(SUM(movement_count), 0), 1) as units_per_transaction,\n",
    "    ROUND(SUM(total_movement_value) / NULLIF(SUM(total_units_moved), 0), 2) as avg_unit_value\n",
    "    \n",
    "FROM movement_summary\n",
    "GROUP BY \n",
    "    movement_type, movement_reason, movement_flow, region_flow,\n",
    "    category_level_1, price_tier\n",
    "HAVING SUM(movement_count) > 5\n",
    "ORDER BY total_value DESC\n",
    "LIMIT 50;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- 2.2 Supply Chain Efficiency & Lead Times\n",
    "WITH supply_metrics AS (\n",
    "    SELECT \n",
    "        p.category_level_1,\n",
    "        p.category_level_2,\n",
    "        p.brand,\n",
    "        l.location_type,\n",
    "        l.region,\n",
    "        \n",
    "        -- Receipt analysis (supplier to warehouse)\n",
    "        COUNT(CASE WHEN im.movement_type = 'receipt' THEN 1 END) as receipts_count,\n",
    "        SUM(CASE WHEN im.movement_type = 'receipt' THEN im.quantity END) as total_received_units,\n",
    "        AVG(CASE WHEN im.movement_type = 'receipt' \n",
    "            THEN DATEDIFF(im.completion_date, im.request_date) END) as avg_receipt_lead_time,\n",
    "        \n",
    "        -- Transfer analysis (warehouse to store)\n",
    "        COUNT(CASE WHEN im.movement_type = 'transfer' THEN 1 END) as transfers_count,\n",
    "        SUM(CASE WHEN im.movement_type = 'transfer' THEN im.quantity END) as total_transferred_units,\n",
    "        AVG(CASE WHEN im.movement_type = 'transfer' \n",
    "            THEN DATEDIFF(im.completion_date, im.request_date) END) as avg_transfer_lead_time,\n",
    "            \n",
    "        -- Returns processing\n",
    "        COUNT(CASE WHEN im.movement_type = 'return' THEN 1 END) as returns_count,\n",
    "        SUM(CASE WHEN im.movement_type = 'return' THEN im.quantity END) as total_returned_units,\n",
    "        AVG(CASE WHEN im.movement_type = 'return' \n",
    "            THEN DATEDIFF(im.completion_date, im.request_date) END) as avg_return_processing_time,\n",
    "            \n",
    "        -- Adjustments (cycle counts, damage, etc.)\n",
    "        COUNT(CASE WHEN im.movement_type = 'adjustment' THEN 1 END) as adjustments_count,\n",
    "        SUM(CASE WHEN im.movement_type = 'adjustment' THEN ABS(im.quantity) END) as total_adjusted_units,\n",
    "        SUM(CASE WHEN im.movement_type = 'adjustment' AND im.quantity > 0 \n",
    "            THEN im.quantity ELSE 0 END) as positive_adjustments,\n",
    "        SUM(CASE WHEN im.movement_type = 'adjustment' AND im.quantity < 0 \n",
    "            THEN ABS(im.quantity) ELSE 0 END) as negative_adjustments\n",
    "        \n",
    "    FROM juan_dev.retail.gold_inventory_movement_fact im\n",
    "    JOIN juan_dev.retail.gold_product_dim p ON im.product_key = p.product_key\n",
    "    LEFT JOIN juan_dev.retail.gold_location_dim l ON im.to_location_key = l.location_key\n",
    "    WHERE im.date_key >= (\n",
    "        SELECT date_key \n",
    "        FROM juan_dev.retail.gold_date_dim \n",
    "        WHERE calendar_date = DATE_SUB(CURRENT_DATE, 90)\n",
    "    )\n",
    "    GROUP BY p.category_level_1, p.category_level_2, p.brand, l.location_type, l.region\n",
    ")\n",
    "SELECT \n",
    "    category_level_1,\n",
    "    category_level_2,\n",
    "    location_type,\n",
    "    region,\n",
    "    \n",
    "    -- Volume metrics\n",
    "    receipts_count,\n",
    "    total_received_units,\n",
    "    transfers_count,\n",
    "    total_transferred_units,\n",
    "    returns_count,\n",
    "    total_returned_units,\n",
    "    \n",
    "    -- Efficiency metrics\n",
    "    ROUND(avg_receipt_lead_time, 1) as avg_receipt_days,\n",
    "    ROUND(avg_transfer_lead_time, 1) as avg_transfer_days,\n",
    "    ROUND(avg_return_processing_time, 1) as avg_return_process_days,\n",
    "    \n",
    "    -- Accuracy metrics  \n",
    "    adjustments_count,\n",
    "    total_adjusted_units,\n",
    "    ROUND(positive_adjustments * 100.0 / NULLIF(total_adjusted_units, 0), 1) as positive_adj_pct,\n",
    "    ROUND(negative_adjustments * 100.0 / NULLIF(total_adjusted_units, 0), 1) as negative_adj_pct,\n",
    "    \n",
    "    -- Operational ratios\n",
    "    ROUND(total_returned_units * 100.0 / NULLIF(total_transferred_units, 0), 2) as return_rate_pct,\n",
    "    ROUND(total_adjusted_units * 100.0 / NULLIF(total_received_units, 0), 2) as adjustment_rate_pct\n",
    "    \n",
    "FROM supply_metrics\n",
    "WHERE receipts_count > 0 OR transfers_count > 0\n",
    "ORDER BY total_received_units DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 🏪 Location Performance & Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- 3.1 Location Operational Performance\n",
    "WITH location_metrics AS (\n",
    "    SELECT \n",
    "        l.location_key,\n",
    "        l.location_name,\n",
    "        l.location_type,\n",
    "        l.region,\n",
    "        l.selling_sqft,\n",
    "        l.total_sqft,\n",
    "        \n",
    "        -- Current inventory position\n",
    "        COUNT(DISTINCT i.product_key) as unique_products_stocked,\n",
    "        SUM(i.quantity_on_hand) as total_units_on_hand,\n",
    "        SUM(i.quantity_available) as total_available_units,\n",
    "        SUM(i.inventory_value_cost) as total_inventory_cost,\n",
    "        SUM(i.inventory_value_retail) as total_inventory_retail,\n",
    "        \n",
    "        -- Inventory health\n",
    "        SUM(CASE WHEN i.is_stockout THEN 1 ELSE 0 END) as stockout_skus,\n",
    "        SUM(CASE WHEN i.is_overstock THEN 1 ELSE 0 END) as overstock_skus,\n",
    "        AVG(i.days_of_supply) as avg_days_supply,\n",
    "        AVG(i.stock_cover_days) as avg_stock_cover,\n",
    "        \n",
    "        -- Sales performance (last 30 days)\n",
    "        COALESCE(sales.transaction_count, 0) as sales_transactions,\n",
    "        COALESCE(sales.total_revenue, 0) as sales_revenue,\n",
    "        COALESCE(sales.total_units_sold, 0) as units_sold,\n",
    "        COALESCE(sales.unique_customers, 0) as unique_customers,\n",
    "        \n",
    "        -- Movement activity (last 30 days)\n",
    "        COALESCE(movements.inbound_movements, 0) as inbound_movements,\n",
    "        COALESCE(movements.outbound_movements, 0) as outbound_movements,\n",
    "        COALESCE(movements.inbound_units, 0) as inbound_units,\n",
    "        COALESCE(movements.outbound_units, 0) as outbound_units\n",
    "        \n",
    "    FROM juan_dev.retail.gold_location_dim l\n",
    "    \n",
    "    -- Current inventory snapshot\n",
    "    LEFT JOIN juan_dev.retail.gold_inventory_fact i \n",
    "        ON l.location_key = i.location_key\n",
    "        AND i.date_key = (\n",
    "            SELECT MAX(date_key) \n",
    "            FROM juan_dev.retail.gold_inventory_fact\n",
    "        )\n",
    "    \n",
    "    -- Sales performance (last 30 days)\n",
    "    LEFT JOIN (\n",
    "        SELECT \n",
    "            location_key,\n",
    "            COUNT(DISTINCT transaction_id) as transaction_count,\n",
    "            SUM(net_sales_amount) as total_revenue,\n",
    "            SUM(quantity_sold) as total_units_sold,\n",
    "            COUNT(DISTINCT customer_key) as unique_customers\n",
    "        FROM juan_dev.retail.gold_sales_fact\n",
    "        WHERE date_key >= (\n",
    "            SELECT date_key \n",
    "            FROM juan_dev.retail.gold_date_dim \n",
    "            WHERE calendar_date = DATE_SUB(CURRENT_DATE, 30)\n",
    "        )\n",
    "        AND is_return = false\n",
    "        GROUP BY location_key\n",
    "    ) sales ON l.location_key = sales.location_key\n",
    "    \n",
    "    -- Movement activity (last 30 days)\n",
    "    LEFT JOIN (\n",
    "        SELECT \n",
    "            COALESCE(to_location_key, from_location_key) as location_key,\n",
    "            SUM(CASE WHEN to_location_key IS NOT NULL THEN 1 ELSE 0 END) as inbound_movements,\n",
    "            SUM(CASE WHEN from_location_key IS NOT NULL THEN 1 ELSE 0 END) as outbound_movements,\n",
    "            SUM(CASE WHEN to_location_key IS NOT NULL THEN quantity ELSE 0 END) as inbound_units,\n",
    "            SUM(CASE WHEN from_location_key IS NOT NULL THEN quantity ELSE 0 END) as outbound_units\n",
    "        FROM juan_dev.retail.gold_inventory_movement_fact\n",
    "        WHERE date_key >= (\n",
    "            SELECT date_key \n",
    "            FROM juan_dev.retail.gold_date_dim \n",
    "            WHERE calendar_date = DATE_SUB(CURRENT_DATE, 30)\n",
    "        )\n",
    "        GROUP BY COALESCE(to_location_key, from_location_key)\n",
    "    ) movements ON l.location_key = movements.location_key\n",
    "    \n",
    "    WHERE l.is_active = true\n",
    "    GROUP BY \n",
    "        l.location_key, l.location_name, l.location_type, l.region, \n",
    "        l.selling_sqft, l.total_sqft, sales.transaction_count, sales.total_revenue,\n",
    "        sales.total_units_sold, sales.unique_customers, movements.inbound_movements,\n",
    "        movements.outbound_movements, movements.inbound_units, movements.outbound_units\n",
    ")\n",
    "SELECT \n",
    "    location_name,\n",
    "    location_type,\n",
    "    region,\n",
    "    \n",
    "    -- Inventory metrics\n",
    "    unique_products_stocked,\n",
    "    total_units_on_hand,\n",
    "    ROUND(total_inventory_cost, 2) as inventory_investment,\n",
    "    ROUND(total_inventory_retail, 2) as inventory_retail_value,\n",
    "    \n",
    "    -- Health indicators\n",
    "    stockout_skus,\n",
    "    overstock_skus,\n",
    "    ROUND(stockout_skus * 100.0 / NULLIF(unique_products_stocked, 0), 1) as stockout_rate_pct,\n",
    "    ROUND(overstock_skus * 100.0 / NULLIF(unique_products_stocked, 0), 1) as overstock_rate_pct,\n",
    "    ROUND(avg_days_supply, 1) as avg_days_supply,\n",
    "    \n",
    "    -- Sales performance\n",
    "    sales_transactions,\n",
    "    ROUND(sales_revenue, 2) as sales_revenue_30d,\n",
    "    units_sold as units_sold_30d,\n",
    "    unique_customers as customers_30d,\n",
    "    \n",
    "    -- Movement activity\n",
    "    inbound_movements + outbound_movements as total_movements_30d,\n",
    "    inbound_units + outbound_units as total_units_moved_30d,\n",
    "    \n",
    "    -- Efficiency ratios\n",
    "    CASE \n",
    "        WHEN selling_sqft > 0 \n",
    "        THEN ROUND(sales_revenue / selling_sqft, 2) \n",
    "        ELSE NULL \n",
    "    END as revenue_per_sqft_30d,\n",
    "    \n",
    "    CASE \n",
    "        WHEN total_inventory_cost > 0 \n",
    "        THEN ROUND(sales_revenue * 365.0 / (30 * total_inventory_cost), 2)\n",
    "        ELSE NULL \n",
    "    END as inventory_turns_annualized,\n",
    "    \n",
    "    ROUND(units_sold * 100.0 / NULLIF(total_available_units, 0), 2) as sell_through_rate_30d_pct\n",
    "    \n",
    "FROM location_metrics\n",
    "ORDER BY \n",
    "    CASE location_type \n",
    "        WHEN 'store' THEN 1 \n",
    "        WHEN 'warehouse' THEN 2 \n",
    "        WHEN 'dc' THEN 3 \n",
    "        ELSE 4 \n",
    "    END,\n",
    "    sales_revenue DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- 3.2 Cross-Location Inventory Distribution Analysis\n",
    "WITH product_distribution AS (\n",
    "    SELECT \n",
    "        p.product_key,\n",
    "        p.sku,\n",
    "        p.product_name,\n",
    "        p.category_level_2,\n",
    "        p.brand,\n",
    "        p.price_tier,\n",
    "        \n",
    "        -- Distribution across location types\n",
    "        SUM(CASE WHEN l.location_type = 'store' THEN i.quantity_on_hand ELSE 0 END) as store_inventory,\n",
    "        SUM(CASE WHEN l.location_type = 'warehouse' THEN i.quantity_on_hand ELSE 0 END) as warehouse_inventory,\n",
    "        SUM(CASE WHEN l.location_type = 'dc' THEN i.quantity_on_hand ELSE 0 END) as dc_inventory,\n",
    "        SUM(i.quantity_on_hand) as total_network_inventory,\n",
    "        \n",
    "        -- Distribution across regions\n",
    "        SUM(CASE WHEN l.region = 'Northeast' THEN i.quantity_on_hand ELSE 0 END) as northeast_inventory,\n",
    "        SUM(CASE WHEN l.region = 'Southeast' THEN i.quantity_on_hand ELSE 0 END) as southeast_inventory,\n",
    "        SUM(CASE WHEN l.region = 'Midwest' THEN i.quantity_on_hand ELSE 0 END) as midwest_inventory,\n",
    "        SUM(CASE WHEN l.region = 'West' THEN i.quantity_on_hand ELSE 0 END) as west_inventory,\n",
    "        SUM(CASE WHEN l.region = 'Southwest' THEN i.quantity_on_hand ELSE 0 END) as southwest_inventory,\n",
    "        \n",
    "        -- Location counts\n",
    "        COUNT(DISTINCT CASE WHEN i.quantity_on_hand > 0 THEN l.location_key END) as locations_with_stock,\n",
    "        COUNT(DISTINCT l.location_key) as total_locations,\n",
    "        \n",
    "        -- Stock concentration\n",
    "        MAX(i.quantity_on_hand) as max_location_stock,\n",
    "        MIN(CASE WHEN i.quantity_on_hand > 0 THEN i.quantity_on_hand END) as min_location_stock,\n",
    "        STDDEV(i.quantity_on_hand) as stock_distribution_stddev,\n",
    "        \n",
    "        -- Financial distribution\n",
    "        SUM(i.inventory_value_retail) as total_retail_value\n",
    "        \n",
    "    FROM juan_dev.retail.gold_product_dim p\n",
    "    JOIN juan_dev.retail.gold_inventory_fact i ON p.product_key = i.product_key\n",
    "    JOIN juan_dev.retail.gold_location_dim l ON i.location_key = l.location_key\n",
    "    WHERE i.date_key = (\n",
    "        SELECT MAX(date_key) \n",
    "        FROM juan_dev.retail.gold_inventory_fact\n",
    "    )\n",
    "    AND p.is_active = true\n",
    "    AND l.is_active = true\n",
    "    GROUP BY p.product_key, p.sku, p.product_name, p.category_level_2, p.brand, p.price_tier\n",
    "),\n",
    "distribution_analysis AS (\n",
    "    SELECT \n",
    "        *,\n",
    "        -- Location type distribution percentages\n",
    "        ROUND(store_inventory * 100.0 / NULLIF(total_network_inventory, 0), 1) as store_pct,\n",
    "        ROUND(warehouse_inventory * 100.0 / NULLIF(total_network_inventory, 0), 1) as warehouse_pct,\n",
    "        ROUND(dc_inventory * 100.0 / NULLIF(total_network_inventory, 0), 1) as dc_pct,\n",
    "        \n",
    "        -- Regional distribution balance (coefficient of variation)\n",
    "        CASE \n",
    "            WHEN total_network_inventory > 0 THEN\n",
    "                SQRT(\n",
    "                    POWER(northeast_inventory - total_network_inventory/5.0, 2) +\n",
    "                    POWER(southeast_inventory - total_network_inventory/5.0, 2) +\n",
    "                    POWER(midwest_inventory - total_network_inventory/5.0, 2) +\n",
    "                    POWER(west_inventory - total_network_inventory/5.0, 2) +\n",
    "                    POWER(southwest_inventory - total_network_inventory/5.0, 2)\n",
    "                ) / (total_network_inventory/5.0)\n",
    "            ELSE 0\n",
    "        END as regional_imbalance_score,\n",
    "        \n",
    "        -- Stock coverage\n",
    "        ROUND(locations_with_stock * 100.0 / NULLIF(total_locations, 0), 1) as location_coverage_pct,\n",
    "        \n",
    "        -- Concentration risk (max location as % of total)\n",
    "        ROUND(max_location_stock * 100.0 / NULLIF(total_network_inventory, 0), 1) as max_concentration_pct\n",
    "        \n",
    "    FROM product_distribution\n",
    "    WHERE total_network_inventory > 0\n",
    ")\n",
    "SELECT \n",
    "    category_level_2,\n",
    "    price_tier,\n",
    "    COUNT(*) as product_count,\n",
    "    SUM(total_network_inventory) as total_units,\n",
    "    ROUND(SUM(total_retail_value), 2) as total_value,\n",
    "    \n",
    "    -- Average distribution patterns\n",
    "    ROUND(AVG(store_pct), 1) as avg_store_pct,\n",
    "    ROUND(AVG(warehouse_pct), 1) as avg_warehouse_pct,\n",
    "    ROUND(AVG(dc_pct), 1) as avg_dc_pct,\n",
    "    \n",
    "    -- Distribution health metrics\n",
    "    ROUND(AVG(location_coverage_pct), 1) as avg_location_coverage_pct,\n",
    "    ROUND(AVG(regional_imbalance_score), 2) as avg_regional_imbalance,\n",
    "    ROUND(AVG(max_concentration_pct), 1) as avg_max_concentration_pct,\n",
    "    \n",
    "    -- Risk indicators\n",
    "    SUM(CASE WHEN location_coverage_pct < 50 THEN 1 ELSE 0 END) as low_coverage_products,\n",
    "    SUM(CASE WHEN max_concentration_pct > 50 THEN 1 ELSE 0 END) as high_concentration_products,\n",
    "    SUM(CASE WHEN regional_imbalance_score > 1.5 THEN 1 ELSE 0 END) as imbalanced_products\n",
    "    \n",
    "FROM distribution_analysis\n",
    "GROUP BY category_level_2, price_tier\n",
    "HAVING COUNT(*) >= 5\n",
    "ORDER BY total_value DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 📊 Demand Planning & Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- 4.1 Demand Forecast Accuracy Analysis\n",
    "WITH forecast_vs_actual AS (\n",
    "    SELECT \n",
    "        df.product_key,\n",
    "        p.sku,\n",
    "        p.product_name,\n",
    "        p.category_level_1,\n",
    "        p.category_level_2,\n",
    "        p.brand,\n",
    "        df.location_key,\n",
    "        l.location_name,\n",
    "        l.location_type,\n",
    "        l.region,\n",
    "        df.forecast_date,\n",
    "        df.forecast_horizon_days,\n",
    "        df.forecasted_demand,\n",
    "        df.confidence_interval_lower,\n",
    "        df.confidence_interval_upper,\n",
    "        \n",
    "        -- Actual sales for the forecasted period\n",
    "        COALESCE(actual.actual_sales, 0) as actual_demand,\n",
    "        \n",
    "        -- Forecast accuracy metrics\n",
    "        ABS(df.forecasted_demand - COALESCE(actual.actual_sales, 0)) as absolute_error,\n",
    "        df.forecasted_demand - COALESCE(actual.actual_sales, 0) as forecast_bias,\n",
    "        \n",
    "        CASE \n",
    "            WHEN COALESCE(actual.actual_sales, 0) > 0 \n",
    "            THEN ABS(df.forecasted_demand - COALESCE(actual.actual_sales, 0)) * 100.0 / actual.actual_sales\n",
    "            ELSE NULL\n",
    "        END as mape_percent,\n",
    "        \n",
    "        -- Confidence interval accuracy\n",
    "        CASE \n",
    "            WHEN COALESCE(actual.actual_sales, 0) BETWEEN df.confidence_interval_lower AND df.confidence_interval_upper \n",
    "            THEN 1 ELSE 0 \n",
    "        END as within_confidence_interval\n",
    "        \n",
    "    FROM juan_dev.retail.gold_demand_forecast_fact df\n",
    "    JOIN juan_dev.retail.gold_product_dim p ON df.product_key = p.product_key\n",
    "    JOIN juan_dev.retail.gold_location_dim l ON df.location_key = l.location_key\n",
    "    \n",
    "    -- Get actual sales for the forecasted period\n",
    "    LEFT JOIN (\n",
    "        SELECT \n",
    "            s.product_key,\n",
    "            s.location_key,\n",
    "            -- Match forecast period (assuming 7-day forecast horizon for this example)\n",
    "            d.calendar_date as forecast_target_date,\n",
    "            SUM(s.quantity_sold) as actual_sales\n",
    "        FROM juan_dev.retail.gold_sales_fact s\n",
    "        JOIN juan_dev.retail.gold_date_dim d ON s.date_key = d.date_key\n",
    "        WHERE s.is_return = false\n",
    "        GROUP BY s.product_key, s.location_key, d.calendar_date\n",
    "    ) actual ON df.product_key = actual.product_key \n",
    "        AND df.location_key = actual.location_key\n",
    "        AND actual.forecast_target_date = DATE_ADD(df.forecast_date, df.forecast_horizon_days)\n",
    "    \n",
    "    WHERE df.forecast_date >= DATE_SUB(CURRENT_DATE, 60)  -- Last 60 days of forecasts\n",
    "        AND df.forecast_date <= DATE_SUB(CURRENT_DATE, 7)   -- Allow time for actuals\n",
    "),\n",
    "accuracy_summary AS (\n",
    "    SELECT \n",
    "        category_level_1,\n",
    "        category_level_2,\n",
    "        location_type,\n",
    "        region,\n",
    "        forecast_horizon_days,\n",
    "        \n",
    "        COUNT(*) as forecast_count,\n",
    "        COUNT(CASE WHEN actual_demand IS NOT NULL THEN 1 END) as forecasts_with_actuals,\n",
    "        \n",
    "        -- Central tendency metrics\n",
    "        SUM(forecasted_demand) as total_forecasted,\n",
    "        SUM(actual_demand) as total_actual,\n",
    "        AVG(forecasted_demand) as avg_forecasted,\n",
    "        AVG(actual_demand) as avg_actual,\n",
    "        \n",
    "        -- Accuracy metrics\n",
    "        AVG(absolute_error) as mean_absolute_error,\n",
    "        AVG(forecast_bias) as mean_bias,\n",
    "        AVG(mape_percent) as mean_absolute_percentage_error,\n",
    "        SQRT(AVG(POWER(forecast_bias, 2))) as root_mean_squared_error,\n",
    "        \n",
    "        -- Confidence interval performance\n",
    "        AVG(within_confidence_interval) * 100 as confidence_interval_hit_rate,\n",
    "        \n",
    "        -- Directional accuracy\n",
    "        SUM(CASE \n",
    "            WHEN (forecasted_demand > 0 AND actual_demand > 0) \n",
    "              OR (forecasted_demand = 0 AND actual_demand = 0) \n",
    "            THEN 1 ELSE 0 \n",
    "        END) * 100.0 / COUNT(*) as directional_accuracy_pct\n",
    "        \n",
    "    FROM forecast_vs_actual\n",
    "    WHERE actual_demand IS NOT NULL  -- Only include where we have actuals\n",
    "    GROUP BY category_level_1, category_level_2, location_type, region, forecast_horizon_days\n",
    ")\n",
    "SELECT \n",
    "    category_level_1,\n",
    "    category_level_2,\n",
    "    location_type,\n",
    "    region,\n",
    "    forecast_horizon_days,\n",
    "    forecast_count,\n",
    "    forecasts_with_actuals,\n",
    "    \n",
    "    ROUND(total_forecasted, 0) as total_forecasted,\n",
    "    ROUND(total_actual, 0) as total_actual,\n",
    "    ROUND((total_forecasted - total_actual) * 100.0 / NULLIF(total_actual, 0), 1) as total_bias_pct,\n",
    "    \n",
    "    ROUND(mean_absolute_error, 2) as mae,\n",
    "    ROUND(mean_bias, 2) as mean_bias,\n",
    "    ROUND(mean_absolute_percentage_error, 1) as mape_pct,\n",
    "    ROUND(root_mean_squared_error, 2) as rmse,\n",
    "    \n",
    "    ROUND(confidence_interval_hit_rate, 1) as ci_hit_rate_pct,\n",
    "    ROUND(directional_accuracy_pct, 1) as directional_accuracy_pct\n",
    "    \n",
    "FROM accuracy_summary\n",
    "WHERE forecasts_with_actuals >= 5\n",
    "ORDER BY \n",
    "    mean_absolute_percentage_error ASC,\n",
    "    category_level_1, location_type;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- 4.2 Inventory Planning Recommendations\n",
    "WITH current_position AS (\n",
    "    SELECT \n",
    "        i.product_key,\n",
    "        i.location_key,\n",
    "        p.sku,\n",
    "        p.product_name,\n",
    "        p.category_level_2,\n",
    "        p.brand,\n",
    "        l.location_name,\n",
    "        l.location_type,\n",
    "        l.region,\n",
    "        \n",
    "        -- Current inventory status\n",
    "        i.quantity_on_hand,\n",
    "        i.quantity_available,\n",
    "        i.quantity_reserved,\n",
    "        i.quantity_in_transit,\n",
    "        i.days_of_supply,\n",
    "        i.reorder_point,\n",
    "        i.reorder_quantity,\n",
    "        i.is_stockout,\n",
    "        i.is_overstock,\n",
    "        \n",
    "        -- Financial metrics\n",
    "        i.inventory_value_cost,\n",
    "        i.inventory_value_retail,\n",
    "        p.base_price,\n",
    "        p.unit_cost\n",
    "        \n",
    "    FROM juan_dev.retail.gold_inventory_fact i\n",
    "    JOIN juan_dev.retail.gold_product_dim p ON i.product_key = p.product_key\n",
    "    JOIN juan_dev.retail.gold_location_dim l ON i.location_key = l.location_key\n",
    "    WHERE i.date_key = (\n",
    "        SELECT MAX(date_key) \n",
    "        FROM juan_dev.retail.gold_inventory_fact\n",
    "    )\n",
    "    AND p.is_active = true\n",
    "    AND l.is_active = true\n",
    "),\n",
    "sales_velocity AS (\n",
    "    SELECT \n",
    "        s.product_key,\n",
    "        s.location_key,\n",
    "        \n",
    "        -- Recent sales performance (last 30 days)\n",
    "        SUM(s.quantity_sold) as units_sold_30d,\n",
    "        COUNT(DISTINCT s.date_key) as selling_days_30d,\n",
    "        AVG(s.quantity_sold) as avg_daily_sales,\n",
    "        STDDEV(s.quantity_sold) as sales_volatility,\n",
    "        \n",
    "        -- Calculate velocity trends\n",
    "        SUM(CASE \n",
    "            WHEN d.calendar_date >= DATE_SUB(CURRENT_DATE, 15) \n",
    "            THEN s.quantity_sold ELSE 0 \n",
    "        END) * 2 as units_sold_last_15d_annualized,\n",
    "        \n",
    "        SUM(CASE \n",
    "            WHEN d.calendar_date >= DATE_SUB(CURRENT_DATE, 7) \n",
    "            THEN s.quantity_sold ELSE 0 \n",
    "        END) * 4.28 as units_sold_last_7d_annualized\n",
    "        \n",
    "    FROM juan_dev.retail.gold_sales_fact s\n",
    "    JOIN juan_dev.retail.gold_date_dim d ON s.date_key = d.date_key\n",
    "    WHERE d.calendar_date >= DATE_SUB(CURRENT_DATE, 30)\n",
    "        AND s.is_return = false\n",
    "    GROUP BY s.product_key, s.location_key\n",
    "),\n",
    "future_demand AS (\n",
    "    SELECT \n",
    "        df.product_key,\n",
    "        df.location_key,\n",
    "        AVG(df.forecasted_demand) as avg_forecasted_demand_7d,\n",
    "        SUM(df.forecasted_demand) as total_forecasted_demand_7d\n",
    "    FROM juan_dev.retail.gold_demand_forecast_fact df\n",
    "    WHERE df.forecast_date = CURRENT_DATE\n",
    "        AND df.forecast_horizon_days <= 7\n",
    "    GROUP BY df.product_key, df.location_key\n",
    "),\n",
    "planning_analysis AS (\n",
    "    SELECT \n",
    "        cp.*,\n",
    "        \n",
    "        -- Sales metrics\n",
    "        COALESCE(sv.units_sold_30d, 0) as units_sold_30d,\n",
    "        COALESCE(sv.avg_daily_sales, 0) as avg_daily_sales,\n",
    "        COALESCE(sv.sales_volatility, 0) as sales_volatility,\n",
    "        COALESCE(fd.avg_forecasted_demand_7d, 0) as forecasted_daily_demand,\n",
    "        \n",
    "        -- Calculate recommended actions\n",
    "        CASE \n",
    "            WHEN cp.quantity_available <= cp.reorder_point \n",
    "                AND COALESCE(sv.avg_daily_sales, 0) > 0 \n",
    "            THEN cp.reorder_quantity\n",
    "            WHEN cp.is_stockout \n",
    "            THEN GREATEST(cp.reorder_quantity, COALESCE(fd.total_forecasted_demand_7d, 0) * 2)\n",
    "            ELSE 0\n",
    "        END as recommended_order_quantity,\n",
    "        \n",
    "        -- Risk assessment\n",
    "        CASE \n",
    "            WHEN cp.is_stockout THEN 'CRITICAL - Stockout'\n",
    "            WHEN cp.quantity_available <= cp.reorder_point THEN 'HIGH - Below Reorder Point'\n",
    "            WHEN cp.days_of_supply <= 7 THEN 'MEDIUM - Low Stock'\n",
    "            WHEN cp.is_overstock THEN 'LOW - Overstock'\n",
    "            ELSE 'NORMAL'\n",
    "        END as risk_level,\n",
    "        \n",
    "        -- Velocity trend\n",
    "        CASE \n",
    "            WHEN COALESCE(sv.units_sold_last_7d_annualized, 0) > COALESCE(sv.units_sold_30d, 0) * 1.2 \n",
    "            THEN 'ACCELERATING'\n",
    "            WHEN COALESCE(sv.units_sold_last_7d_annualized, 0) < COALESCE(sv.units_sold_30d, 0) * 0.8 \n",
    "            THEN 'DECELERATING'\n",
    "            ELSE 'STABLE'\n",
    "        END as velocity_trend\n",
    "        \n",
    "    FROM current_position cp\n",
    "    LEFT JOIN sales_velocity sv ON cp.product_key = sv.product_key AND cp.location_key = sv.location_key\n",
    "    LEFT JOIN future_demand fd ON cp.product_key = fd.product_key AND cp.location_key = fd.location_key\n",
    ")\n",
    "SELECT \n",
    "    sku,\n",
    "    product_name,\n",
    "    location_name,\n",
    "    location_type,\n",
    "    region,\n",
    "    category_level_2,\n",
    "    \n",
    "    -- Current status\n",
    "    quantity_on_hand,\n",
    "    quantity_available,\n",
    "    quantity_in_transit,\n",
    "    days_of_supply,\n",
    "    risk_level,\n",
    "    \n",
    "    -- Sales insights\n",
    "    units_sold_30d,\n",
    "    ROUND(avg_daily_sales, 2) as avg_daily_sales,\n",
    "    ROUND(forecasted_daily_demand, 2) as forecasted_daily_demand,\n",
    "    velocity_trend,\n",
    "    \n",
    "    -- Recommendations\n",
    "    recommended_order_quantity,\n",
    "    ROUND(recommended_order_quantity * unit_cost, 2) as recommended_order_value,\n",
    "    \n",
    "    -- Financial impact\n",
    "    ROUND(inventory_value_cost, 2) as current_investment,\n",
    "    ROUND(\n",
    "        CASE \n",
    "            WHEN avg_daily_sales > 0 \n",
    "            THEN (base_price - unit_cost) * avg_daily_sales * 30\n",
    "            ELSE 0 \n",
    "        END, 2\n",
    "    ) as potential_monthly_margin\n",
    "    \n",
    "FROM planning_analysis\n",
    "WHERE risk_level IN ('CRITICAL - Stockout', 'HIGH - Below Reorder Point', 'MEDIUM - Low Stock')\n",
    "   OR recommended_order_quantity > 0\n",
    "   OR velocity_trend = 'ACCELERATING'\n",
    "ORDER BY \n",
    "    CASE risk_level \n",
    "        WHEN 'CRITICAL - Stockout' THEN 1\n",
    "        WHEN 'HIGH - Below Reorder Point' THEN 2  \n",
    "        WHEN 'MEDIUM - Low Stock' THEN 3\n",
    "        ELSE 4\n",
    "    END,\n",
    "    potential_monthly_margin DESC\n",
    "LIMIT 100;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ⚠️ Stockout & Overstock Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- 5.1 Stockout Impact and Lost Sales Analysis\n",
    "WITH stockout_events AS (\n",
    "    SELECT \n",
    "        i.product_key,\n",
    "        i.location_key,\n",
    "        p.sku,\n",
    "        p.product_name,\n",
    "        p.category_level_2,\n",
    "        p.brand,\n",
    "        p.base_price,\n",
    "        l.location_name,\n",
    "        l.location_type,\n",
    "        l.region,\n",
    "        d.calendar_date as stockout_date,\n",
    "        d.fiscal_quarter,\n",
    "        d.is_weekend,\n",
    "        d.is_holiday,\n",
    "        i.quantity_on_hand,\n",
    "        i.quantity_reserved,\n",
    "        i.is_stockout\n",
    "    FROM juan_dev.retail.gold_inventory_fact i\n",
    "    JOIN juan_dev.retail.gold_product_dim p ON i.product_key = p.product_key\n",
    "    JOIN juan_dev.retail.gold_location_dim l ON i.location_key = l.location_key\n",
    "    JOIN juan_dev.retail.gold_date_dim d ON i.date_key = d.date_key\n",
    "    WHERE i.is_stockout = true\n",
    "        AND d.calendar_date >= DATE_SUB(CURRENT_DATE, 90)\n",
    "        AND p.is_active = true\n",
    "),\n",
    "pre_stockout_sales AS (\n",
    "    SELECT \n",
    "        s.product_key,\n",
    "        s.location_key,\n",
    "        AVG(s.quantity_sold) as avg_daily_sales_pre_stockout,\n",
    "        AVG(s.net_sales_amount) as avg_daily_revenue_pre_stockout,\n",
    "        STDDEV(s.quantity_sold) as sales_volatility\n",
    "    FROM juan_dev.retail.gold_sales_fact s\n",
    "    JOIN juan_dev.retail.gold_date_dim d ON s.date_key = d.date_key\n",
    "    WHERE d.calendar_date >= DATE_SUB(CURRENT_DATE, 120)\n",
    "        AND d.calendar_date < DATE_SUB(CURRENT_DATE, 90)\n",
    "        AND s.is_return = false\n",
    "    GROUP BY s.product_key, s.location_key\n",
    "),\n",
    "stockout_analysis AS (\n",
    "    SELECT \n",
    "        so.category_level_2,\n",
    "        so.brand,\n",
    "        so.location_type,\n",
    "        so.region,\n",
    "        so.fiscal_quarter,\n",
    "        \n",
    "        -- Stockout frequency metrics\n",
    "        COUNT(*) as stockout_days,\n",
    "        COUNT(DISTINCT so.product_key) as products_with_stockouts,\n",
    "        COUNT(DISTINCT so.location_key) as locations_with_stockouts,\n",
    "        COUNT(DISTINCT CONCAT(so.product_key, '-', so.location_key)) as unique_product_location_stockouts,\n",
    "        \n",
    "        -- Timing analysis\n",
    "        SUM(CASE WHEN so.is_weekend THEN 1 ELSE 0 END) as weekend_stockouts,\n",
    "        SUM(CASE WHEN so.is_holiday THEN 1 ELSE 0 END) as holiday_stockouts,\n",
    "        \n",
    "        -- Lost sales estimation\n",
    "        SUM(COALESCE(pss.avg_daily_sales_pre_stockout, 0)) as estimated_lost_units,\n",
    "        SUM(COALESCE(pss.avg_daily_revenue_pre_stockout, 0)) as estimated_lost_revenue,\n",
    "        \n",
    "        -- Financial impact\n",
    "        AVG(so.base_price) as avg_product_price,\n",
    "        SUM(COALESCE(pss.avg_daily_sales_pre_stockout, 0) * so.base_price) as estimated_lost_retail_value\n",
    "        \n",
    "    FROM stockout_events so\n",
    "    LEFT JOIN pre_stockout_sales pss \n",
    "        ON so.product_key = pss.product_key \n",
    "        AND so.location_key = pss.location_key\n",
    "    GROUP BY \n",
    "        so.category_level_2, so.brand, so.location_type, \n",
    "        so.region, so.fiscal_quarter\n",
    ")\n",
    "SELECT \n",
    "    category_level_2,\n",
    "    location_type,\n",
    "    region,\n",
    "    fiscal_quarter,\n",
    "    \n",
    "    stockout_days,\n",
    "    products_with_stockouts,\n",
    "    locations_with_stockouts,\n",
    "    unique_product_location_stockouts,\n",
    "    \n",
    "    -- Stockout patterns\n",
    "    ROUND(weekend_stockouts * 100.0 / stockout_days, 1) as weekend_stockout_pct,\n",
    "    ROUND(holiday_stockouts * 100.0 / stockout_days, 1) as holiday_stockout_pct,\n",
    "    \n",
    "    -- Lost sales impact\n",
    "    ROUND(estimated_lost_units, 0) as est_lost_units,\n",
    "    ROUND(estimated_lost_revenue, 2) as est_lost_revenue,\n",
    "    ROUND(estimated_lost_retail_value, 2) as est_lost_retail_value,\n",
    "    \n",
    "    -- Average impact per stockout day\n",
    "    ROUND(estimated_lost_units / NULLIF(stockout_days, 0), 1) as avg_lost_units_per_day,\n",
    "    ROUND(estimated_lost_revenue / NULLIF(stockout_days, 0), 2) as avg_lost_revenue_per_day\n",
    "    \n",
    "FROM stockout_analysis\n",
    "WHERE stockout_days > 0\n",
    "ORDER BY estimated_lost_revenue DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- 5.2 Overstock Analysis and Clearance Opportunities\n",
    "WITH overstock_analysis AS (\n",
    "    SELECT \n",
    "        i.product_key,\n",
    "        i.location_key,\n",
    "        p.sku,\n",
    "        p.product_name,\n",
    "        p.category_level_1,\n",
    "        p.category_level_2,\n",
    "        p.brand,\n",
    "        p.season_code,\n",
    "        p.launch_date,\n",
    "        p.end_of_life_date,\n",
    "        p.base_price,\n",
    "        p.unit_cost,\n",
    "        l.location_name,\n",
    "        l.location_type,\n",
    "        l.region,\n",
    "        \n",
    "        -- Current inventory status\n",
    "        i.quantity_on_hand,\n",
    "        i.quantity_available,\n",
    "        i.days_of_supply,\n",
    "        i.stock_cover_days,\n",
    "        i.inventory_value_cost,\n",
    "        i.inventory_value_retail,\n",
    "        i.is_overstock,\n",
    "        \n",
    "        -- Product lifecycle stage\n",
    "        DATEDIFF(CURRENT_DATE, p.launch_date) as days_since_launch,\n",
    "        CASE \n",
    "            WHEN p.end_of_life_date IS NOT NULL \n",
    "            THEN DATEDIFF(p.end_of_life_date, CURRENT_DATE)\n",
    "            ELSE NULL \n",
    "        END as days_until_eol,\n",
    "        \n",
    "        -- Recent sales performance (last 30 days)\n",
    "        COALESCE(recent_sales.units_sold_30d, 0) as units_sold_30d,\n",
    "        COALESCE(recent_sales.revenue_30d, 0) as revenue_30d,\n",
    "        COALESCE(recent_sales.avg_daily_sales, 0) as avg_daily_sales,\n",
    "        COALESCE(recent_sales.selling_days, 0) as selling_days_30d,\n",
    "        \n",
    "        -- Sales velocity trends\n",
    "        COALESCE(recent_sales.units_sold_last_7d, 0) as units_sold_7d,\n",
    "        COALESCE(recent_sales.units_sold_last_14d, 0) as units_sold_14d\n",
    "        \n",
    "    FROM juan_dev.retail.gold_inventory_fact i\n",
    "    JOIN juan_dev.retail.gold_product_dim p ON i.product_key = p.product_key\n",
    "    JOIN juan_dev.retail.gold_location_dim l ON i.location_key = l.location_key\n",
    "    \n",
    "    -- Recent sales data\n",
    "    LEFT JOIN (\n",
    "        SELECT \n",
    "            s.product_key,\n",
    "            s.location_key,\n",
    "            SUM(s.quantity_sold) as units_sold_30d,\n",
    "            SUM(s.net_sales_amount) as revenue_30d,\n",
    "            AVG(s.quantity_sold) as avg_daily_sales,\n",
    "            COUNT(DISTINCT s.date_key) as selling_days,\n",
    "            SUM(CASE \n",
    "                WHEN d.calendar_date >= DATE_SUB(CURRENT_DATE, 7) \n",
    "                THEN s.quantity_sold ELSE 0 \n",
    "            END) as units_sold_last_7d,\n",
    "            SUM(CASE \n",
    "                WHEN d.calendar_date >= DATE_SUB(CURRENT_DATE, 14) \n",
    "                THEN s.quantity_sold ELSE 0 \n",
    "            END) as units_sold_last_14d\n",
    "        FROM juan_dev.retail.gold_sales_fact s\n",
    "        JOIN juan_dev.retail.gold_date_dim d ON s.date_key = d.date_key\n",
    "        WHERE d.calendar_date >= DATE_SUB(CURRENT_DATE, 30)\n",
    "            AND s.is_return = false\n",
    "        GROUP BY s.product_key, s.location_key\n",
    "    ) recent_sales ON i.product_key = recent_sales.product_key \n",
    "        AND i.location_key = recent_sales.location_key\n",
    "    \n",
    "    WHERE i.date_key = (\n",
    "        SELECT MAX(date_key) \n",
    "        FROM juan_dev.retail.gold_inventory_fact\n",
    "    )\n",
    "    AND p.is_active = true\n",
    "    AND (\n",
    "        i.is_overstock = true \n",
    "        OR i.days_of_supply > 60\n",
    "        OR (i.quantity_on_hand > 0 AND recent_sales.units_sold_30d = 0)\n",
    "    )\n",
    "),\n",
    "clearance_recommendations AS (\n",
    "    SELECT \n",
    "        *,\n",
    "        \n",
    "        -- Urgency scoring\n",
    "        CASE \n",
    "            WHEN days_until_eol IS NOT NULL AND days_until_eol <= 30 THEN 'URGENT - EOL Soon'\n",
    "            WHEN units_sold_30d = 0 THEN 'HIGH - No Sales 30d'\n",
    "            WHEN days_of_supply > 90 THEN 'HIGH - Excess Stock'\n",
    "            WHEN units_sold_7d = 0 AND units_sold_14d > 0 THEN 'MEDIUM - Slowing'\n",
    "            WHEN is_overstock THEN 'MEDIUM - Overstock'\n",
    "            ELSE 'LOW'\n",
    "        END as clearance_priority,\n",
    "        \n",
    "        -- Clearance strategy\n",
    "        CASE \n",
    "            WHEN avg_daily_sales > 0 \n",
    "            THEN LEAST(quantity_on_hand * 0.5, avg_daily_sales * 14)  -- 2 weeks of sales or 50% of stock\n",
    "            ELSE quantity_on_hand * 0.3  -- Conservative 30% if no recent sales\n",
    "        END as recommended_clearance_qty,\n",
    "        \n",
    "        -- Financial metrics\n",
    "        CASE \n",
    "            WHEN days_until_eol IS NOT NULL AND days_until_eol <= 30 \n",
    "            THEN base_price * 0.4  -- 60% off for EOL\n",
    "            WHEN units_sold_30d = 0 \n",
    "            THEN base_price * 0.5  -- 50% off for non-movers\n",
    "            WHEN days_of_supply > 90 \n",
    "            THEN base_price * 0.6  -- 40% off for excess stock\n",
    "            ELSE base_price * 0.7  -- 30% off for general overstock\n",
    "        END as recommended_clearance_price,\n",
    "        \n",
    "        -- Potential recovery calculation\n",
    "        inventory_value_cost - (quantity_on_hand * unit_cost) as carrying_cost_risk\n",
    "        \n",
    "    FROM overstock_analysis\n",
    ")\n",
    "SELECT \n",
    "    sku,\n",
    "    product_name,\n",
    "    category_level_2,\n",
    "    location_name,\n",
    "    location_type,\n",
    "    region,\n",
    "    \n",
    "    -- Current position\n",
    "    quantity_on_hand,\n",
    "    days_of_supply,\n",
    "    ROUND(inventory_value_cost, 2) as current_investment,\n",
    "    ROUND(inventory_value_retail, 2) as current_retail_value,\n",
    "    \n",
    "    -- Sales performance\n",
    "    units_sold_30d,\n",
    "    units_sold_7d,\n",
    "    ROUND(avg_daily_sales, 2) as avg_daily_sales,\n",
    "    \n",
    "    -- Lifecycle\n",
    "    days_since_launch,\n",
    "    days_until_eol,\n",
    "    season_code,\n",
    "    \n",
    "    -- Recommendations\n",
    "    clearance_priority,\n",
    "    ROUND(recommended_clearance_qty, 0) as recommended_clearance_qty,\n",
    "    ROUND(base_price, 2) as current_price,\n",
    "    ROUND(recommended_clearance_price, 2) as recommended_clearance_price,\n",
    "    ROUND((base_price - recommended_clearance_price) * 100.0 / base_price, 0) as discount_pct,\n",
    "    \n",
    "    -- Financial impact\n",
    "    ROUND(recommended_clearance_qty * recommended_clearance_price, 2) as potential_clearance_revenue,\n",
    "    ROUND(recommended_clearance_qty * (recommended_clearance_price - unit_cost), 2) as potential_margin,\n",
    "    ROUND(carrying_cost_risk, 2) as carrying_cost_risk\n",
    "    \n",
    "FROM clearance_recommendations\n",
    "ORDER BY \n",
    "    CASE clearance_priority \n",
    "        WHEN 'URGENT - EOL Soon' THEN 1\n",
    "        WHEN 'HIGH - No Sales 30d' THEN 2\n",
    "        WHEN 'HIGH - Excess Stock' THEN 3\n",
    "        WHEN 'MEDIUM - Slowing' THEN 4\n",
    "        WHEN 'MEDIUM - Overstock' THEN 5\n",
    "        ELSE 6\n",
    "    END,\n",
    "    carrying_cost_risk DESC\n",
    "LIMIT 100;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 💰 Financial Inventory Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- 6.1 Inventory Financial Performance Dashboard\n",
    "WITH inventory_financial_metrics AS (\n",
    "    SELECT \n",
    "        p.category_level_1,\n",
    "        p.category_level_2,\n",
    "        p.brand,\n",
    "        p.price_tier,\n",
    "        l.location_type,\n",
    "        l.region,\n",
    "        \n",
    "        -- Current inventory investment\n",
    "        SUM(i.inventory_value_cost) as total_inventory_cost,\n",
    "        SUM(i.inventory_value_retail) as total_inventory_retail,\n",
    "        SUM(i.inventory_value_retail - i.inventory_value_cost) as total_inventory_markup,\n",
    "        SUM(i.quantity_on_hand) as total_units_on_hand,\n",
    "        \n",
    "        -- Inventory composition\n",
    "        COUNT(DISTINCT i.product_key) as unique_products,\n",
    "        COUNT(*) as total_sku_locations,\n",
    "        \n",
    "        -- Health metrics\n",
    "        SUM(CASE WHEN i.is_stockout THEN i.inventory_value_cost ELSE 0 END) as stockout_investment,\n",
    "        SUM(CASE WHEN i.is_overstock THEN i.inventory_value_cost ELSE 0 END) as overstock_investment,\n",
    "        AVG(i.days_of_supply) as avg_days_supply,\n",
    "        \n",
    "        -- Sales performance (last 90 days)\n",
    "        COALESCE(sales_90d.total_revenue, 0) as revenue_90d,\n",
    "        COALESCE(sales_90d.total_units_sold, 0) as units_sold_90d,\n",
    "        COALESCE(sales_90d.total_cost_of_goods, 0) as cogs_90d,\n",
    "        COALESCE(sales_90d.gross_margin, 0) as gross_margin_90d\n",
    "        \n",
    "    FROM juan_dev.retail.gold_inventory_fact i\n",
    "    JOIN juan_dev.retail.gold_product_dim p ON i.product_key = p.product_key\n",
    "    JOIN juan_dev.retail.gold_location_dim l ON i.location_key = l.location_key\n",
    "    \n",
    "    -- Sales performance for turnover calculations\n",
    "    LEFT JOIN (\n",
    "        SELECT \n",
    "            s.product_key,\n",
    "            p_inner.category_level_1,\n",
    "            p_inner.category_level_2,\n",
    "            p_inner.brand,\n",
    "            p_inner.price_tier,\n",
    "            l_inner.location_type,\n",
    "            l_inner.region,\n",
    "            SUM(s.net_sales_amount) as total_revenue,\n",
    "            SUM(s.quantity_sold) as total_units_sold,\n",
    "            SUM(s.quantity_sold * p_inner.unit_cost) as total_cost_of_goods,\n",
    "            SUM(s.net_sales_amount - (s.quantity_sold * p_inner.unit_cost)) as gross_margin\n",
    "        FROM juan_dev.retail.gold_sales_fact s\n",
    "        JOIN juan_dev.retail.gold_product_dim p_inner ON s.product_key = p_inner.product_key\n",
    "        JOIN juan_dev.retail.gold_location_dim l_inner ON s.location_key = l_inner.location_key\n",
    "        JOIN juan_dev.retail.gold_date_dim d ON s.date_key = d.date_key\n",
    "        WHERE d.calendar_date >= DATE_SUB(CURRENT_DATE, 90)\n",
    "            AND s.is_return = false\n",
    "        GROUP BY \n",
    "            s.product_key, p_inner.category_level_1, p_inner.category_level_2,\n",
    "            p_inner.brand, p_inner.price_tier, l_inner.location_type, l_inner.region\n",
    "    ) sales_90d ON p.category_level_1 = sales_90d.category_level_1\n",
    "        AND p.category_level_2 = sales_90d.category_level_2\n",
    "        AND p.brand = sales_90d.brand\n",
    "        AND p.price_tier = sales_90d.price_tier\n",
    "        AND l.location_type = sales_90d.location_type\n",
    "        AND l.region = sales_90d.region\n",
    "    \n",
    "    WHERE i.date_key = (\n",
    "        SELECT MAX(date_key) \n",
    "        FROM juan_dev.retail.gold_inventory_fact\n",
    "    )\n",
    "    AND p.is_active = true\n",
    "    AND l.is_active = true\n",
    "    \n",
    "    GROUP BY \n",
    "        p.category_level_1, p.category_level_2, p.brand, p.price_tier,\n",
    "        l.location_type, l.region, sales_90d.total_revenue, sales_90d.total_units_sold,\n",
    "        sales_90d.total_cost_of_goods, sales_90d.gross_margin\n",
    "),\n",
    "financial_kpis AS (\n",
    "    SELECT \n",
    "        *,\n",
    "        \n",
    "        -- Inventory turns (annualized)\n",
    "        CASE \n",
    "            WHEN total_inventory_cost > 0 \n",
    "            THEN (cogs_90d * 365.0) / (90 * total_inventory_cost)\n",
    "            ELSE 0 \n",
    "        END as inventory_turns_annual,\n",
    "        \n",
    "        -- Sell-through rate (90 days annualized)\n",
    "        CASE \n",
    "            WHEN total_units_on_hand > 0 \n",
    "            THEN (units_sold_90d * 365.0) / (90 * total_units_on_hand) * 100\n",
    "            ELSE 0 \n",
    "        END as sell_through_rate_annual_pct,\n",
    "        \n",
    "        -- ROI metrics\n",
    "        CASE \n",
    "            WHEN total_inventory_cost > 0 \n",
    "            THEN (gross_margin_90d * 365.0) / (90 * total_inventory_cost) * 100\n",
    "            ELSE 0 \n",
    "        END as inventory_roi_annual_pct,\n",
    "        \n",
    "        -- Markup percentages\n",
    "        CASE \n",
    "            WHEN total_inventory_cost > 0 \n",
    "            THEN total_inventory_markup * 100.0 / total_inventory_cost\n",
    "            ELSE 0 \n",
    "        END as markup_percentage,\n",
    "        \n",
    "        -- Health ratios\n",
    "        CASE \n",
    "            WHEN total_inventory_cost > 0 \n",
    "            THEN stockout_investment * 100.0 / total_inventory_cost\n",
    "            ELSE 0 \n",
    "        END as stockout_investment_pct,\n",
    "        \n",
    "        CASE \n",
    "            WHEN total_inventory_cost > 0 \n",
    "            THEN overstock_investment * 100.0 / total_inventory_cost\n",
    "            ELSE 0 \n",
    "        END as overstock_investment_pct\n",
    "        \n",
    "    FROM inventory_financial_metrics\n",
    ")\n",
    "SELECT \n",
    "    category_level_1,\n",
    "    category_level_2,\n",
    "    price_tier,\n",
    "    location_type,\n",
    "    region,\n",
    "    \n",
    "    -- Investment metrics\n",
    "    ROUND(total_inventory_cost, 2) as inventory_investment,\n",
    "    ROUND(total_inventory_retail, 2) as inventory_retail_value,\n",
    "    ROUND(total_inventory_markup, 2) as inventory_markup_value,\n",
    "    total_units_on_hand,\n",
    "    unique_products,\n",
    "    \n",
    "    -- Performance metrics\n",
    "    ROUND(revenue_90d, 2) as revenue_90d,\n",
    "    ROUND(gross_margin_90d, 2) as gross_margin_90d,\n",
    "    ROUND(inventory_turns_annual, 2) as inventory_turns_annual,\n",
    "    ROUND(sell_through_rate_annual_pct, 1) as sell_through_rate_pct,\n",
    "    ROUND(inventory_roi_annual_pct, 1) as inventory_roi_pct,\n",
    "    \n",
    "    -- Efficiency metrics\n",
    "    ROUND(markup_percentage, 1) as markup_pct,\n",
    "    ROUND(avg_days_supply, 1) as avg_days_supply,\n",
    "    \n",
    "    -- Health metrics\n",
    "    ROUND(stockout_investment, 2) as stockout_investment,\n",
    "    ROUND(overstock_investment, 2) as overstock_investment,\n",
    "    ROUND(stockout_investment_pct, 1) as stockout_investment_pct,\n",
    "    ROUND(overstock_investment_pct, 1) as overstock_investment_pct,\n",
    "    \n",
    "    -- Investment concentration\n",
    "    ROUND(total_inventory_cost / NULLIF(unique_products, 0), 2) as avg_investment_per_product,\n",
    "    ROUND(revenue_90d / NULLIF(total_inventory_cost, 0), 2) as revenue_to_investment_ratio_90d\n",
    "    \n",
    "FROM financial_kpis\n",
    "WHERE total_inventory_cost > 100  -- Filter out minimal investments\n",
    "ORDER BY total_inventory_cost DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📋 Summary\n",
    "\n",
    "These queries provide comprehensive inventory and operations analytics covering:\n",
    "\n",
    "**Inventory Health & Optimization:**\n",
    "- Current inventory status dashboard with health indicators\n",
    "- ABC analysis for inventory classification and prioritization\n",
    "\n",
    "**Supply Chain & Movement Analytics:**\n",
    "- Inventory movement flow analysis across the network\n",
    "- Supply chain efficiency metrics and lead time analysis\n",
    "\n",
    "**Location Performance & Operations:**\n",
    "- Location-specific operational performance metrics\n",
    "- Cross-location inventory distribution analysis\n",
    "\n",
    "**Demand Planning & Forecasting:**\n",
    "- Forecast accuracy analysis with MAPE and bias metrics\n",
    "- Inventory planning recommendations with risk assessment\n",
    "\n",
    "**Stockout & Overstock Analysis:**\n",
    "- Stockout impact and lost sales estimation\n",
    "- Overstock analysis with clearance recommendations\n",
    "\n",
    "**Financial Inventory Metrics:**\n",
    "- Comprehensive financial performance dashboard\n",
    "- Inventory turns, ROI, and investment efficiency metrics\n",
    "\n",
    "Each query is optimized for the star schema design and provides actionable insights for inventory managers, operations teams, buyers, and financial analysts to optimize inventory investment and operational efficiency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}